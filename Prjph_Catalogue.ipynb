{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du catalogue de photos\n",
    "\n",
    "## Recherche de photos dans l'arbordescence sous-jacente au répertoire indiqué par l'utilisateur.\n",
    "\n",
    "## Remarques :\n",
    "\n",
    "### ajout du format vidéo .3gp le 24/10/20 19h05\n",
    "\n",
    "\n",
    "### Objectif : avoir un outil permettant de référencer les photos et d'obtenir des statistiques :\n",
    "\n",
    "- permettre une sauvegarde des photos dans un dd unique (les dossiers d'origine sont conservés) tout en permettant\n",
    "de sauvegarder et \n",
    "\n",
    "- référencer d'éventuelles nouvelles photos sans avoir à tout référencer à nouveau (celles déjà\n",
    "référencés seront topées 'déjà présentes'\n",
    "\n",
    "- obtenir des dossiers (albums) constitués de copies de photos par classement souhaité (doublons possibles).\n",
    "\n",
    "Stats :\n",
    "- nombre d'images par année, mois, jour\n",
    "- nombre de doublons\n",
    "- nombre de photos par sujet\n",
    "\n",
    "\n",
    "\n",
    "### A voir : \n",
    "\n",
    "la gestion du réseau (paramétrages sécurisés)\n",
    "\n",
    "la taille de l'image stockée si stockée. A réduire éventuellement.\n",
    "\n",
    "\n",
    "### Priorités :\n",
    "\n",
    "La fonction de copie\n",
    "La création d'albums en fonction des dates.\n",
    "La sauvegarde d'albums sur clés usb (par années, par personne, par lieu).\n",
    "\n",
    "\n",
    "\n",
    "### Prochains points : \n",
    "\n",
    "- Copie des fichiers catalogués dans le matériel de stockage qui aura été choisi.\n",
    "\n",
    "- Vérifier la récupération de la date de fichier : \n",
    "\n",
    "    - Récupérer en priorité la date 'Origine/Prise de vue' des données exif (?) puis st_mtimt, notamment pour les jpg (si modif sur iPhone, alors la valeur est différente de la date de dernière modification (st_mtime).\n",
    "\n",
    "\n",
    "- Ajout d'un appel pour récupérer le nombre total de répertoires dans l'arboresence du répertoire initial\n",
    "  afin de pouvoir avoir une estimation de la durée de traitement.\n",
    "  \n",
    "- Ajout du nombre de fichiers lus (qqsoit le type de fichier) (pour avoir une idée de l'écart)\n",
    "\n",
    "- Notification des traitements sur cahier au fur et à mesure.    \n",
    "\n",
    "- Calcul du nombre de fichier et du volume mémoire avec la requête ci-dessus\n",
    "\n",
    "- Mise sous forme dataFrame de la base et sauvegarde en csv (pour manips sur Excel)\n",
    "\n",
    "- Stats sous Excel\n",
    "\n",
    "- Fin\n",
    "\n",
    "Le volume global va servir à étudier les solutions de stockage des copies.\n",
    "\n",
    "\n",
    "#### Points traités :\n",
    "\n",
    "- Identification de la donnée 'taille mémoire' de l'image (pour calcul du volume global) ----------------OK\n",
    "\n",
    "- Calcul de la taille globale : Requête de calcul de la somme des tailles mémoire -----------------------OK\n",
    "\n",
    "- Lancement d'une requête mongodb sur la bd via python et récupération du résultat dans une variable ----OK\n",
    "\n",
    "- Définition de la liste des extensions 'image' et 'vidéo' ----------------------------------------------OK\n",
    "\n",
    "    - Ajout d'un document 'log' qui contient ------------------------------------------------------------OK\n",
    "    - un titre illustrant le traitement lancé -----------------------------------------------------------OK\n",
    "    - la date -------------------------------------------------------------------------------------------OK\n",
    "    - le répertoire racine paramétré --------------------------------------------------------------------OK\n",
    "    - la liste des répertoires explorés (faire un df au fur et à mesure du print) -----------------------OK\n",
    "    \n",
    "  (utilité : avoir l'historique des répertoires consultés pour éviter de les refaire en cas de doute)\n",
    "\n",
    "\n",
    "\n",
    "### A venir :\n",
    "\n",
    "Fonctions à venir : \n",
    "COPIE - GESTION DES DOUBLONS - RECHERCHE - CLASSEMENT - CREATION D'ALBUMS SELON CRITERES - RECONNAISSANCE\n",
    "\n",
    "ajout de la sauvegarde d'une vignette de l'image dans la bd\n",
    "ajout du référencement des vidéos (=> ajout des types vidéos)\n",
    "faire le point sur les types de fichiers image et vidéo\n",
    "\n",
    "penser à faire un test (copie des répertoires photo, avec écriture bloquée)\n",
    "\n",
    "obtenir la liste des répertoires de photos avant la copie (pour les mettre en écriture interdite)\n",
    "\n",
    "ajout de la fonction COPIE:\n",
    "    même fonctionnement mais avec en plus une copie dans un dossier spécifé\n",
    "    + mise à jour de la bd (ajout événement copie / création enreg avec deux événements - insert et copie)\n",
    "    \n",
    "ajout de la fonction de gestion des doublons\n",
    "    à préciser\n",
    "    \n",
    "définir le lieu de stockage de la bd (cf. volume important si images stockées)\n",
    "\n",
    "\n",
    "### Réalisé\n",
    "\n",
    "21/10 : Les statistiques quantités et volumes par année, mois, jour, catégories, types de fichier (notebook statistiques).\n",
    "\n",
    "15/10 : création réseau. Accès au répertoire partagé.\n",
    "\n",
    "test sur le répertoire partagé\n",
    "\n",
    "ajout du stockage de l'image\n",
    "\n",
    "annulation du stockage de l'image - pourra être effectué ultérieurement.\n",
    "\n",
    "la correction de la récup des données exif (cf. en cours)\n",
    "\n",
    "le traitement de la donnée exif 37500, bytes très longue. A priori, le pop ne fonctionne pas.\n",
    "\n",
    "Répertoire et types de fichiers entrés en paramètres\n",
    "\n",
    "appel à la fonction prjph_listdirectory : récupération dans un dictionnaire des noms des fichiers avec os.listdir contenus dans le répertoire passé en paramètre et de type passé en paramètre également.\n",
    "\n",
    "Avec pour chaque fichier :\n",
    "\n",
    "    - récupération et ajout dans le dictionnaire des métadonnées exif avec PIL getexif (via fnph_getexif)\n",
    "      (avec suppression des données 37500, 37510 et 59932 car trop longues et a priori non utiles\n",
    "      , et suppression des clés dictionnaires)\n",
    "\n",
    "    - récupération et ajout dans le dictionnaire des stats par os.stats avec conversion en dicitonnaire (via fnph_getstats)\n",
    "    \n",
    "Mise à jour de la base mongo avec les fichiers contenus dans la liste obtenue :\n",
    "    \n",
    "    - recherche de la présence du fichier dans la base (par appel à la fonction prjph_alreadyexists\n",
    "    \n",
    "    - si le fichier n'est pas déjà présent : écriture des éléments du dictionnaire de données liées au fichier en cours \n",
    "    \n",
    "    - sinon, mise à jour du document dans la base par ajout d'un champ événement (identifiant unique créé avec la date)\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "### Fonctions cibles :\n",
    "\n",
    "- Demande de répertoire de recherche à l'utilisateur\n",
    "\n",
    "- Recherche d'images dans le répertoire indiqué et l'arborescence sous-jacente\n",
    "    format sélectionné : img, jpeg\n",
    "    \n",
    "- Pour chaque image : \n",
    "\n",
    "    - Récupération des caractéristiques de l'image\n",
    "    \n",
    "        . nom du fichier image\n",
    "        . emplacement d'origine (chemin)\n",
    "        . matériel (nom du disque dur)\n",
    "        . date de prise de vue\n",
    "        . appareil\n",
    "        . date de création du fichier origine\n",
    "        \n",
    "    - Mise à jour de la base de données :\n",
    "    \n",
    "        . date de mise à jour\n",
    "        . caractéristiques de l'image\n",
    "\n",
    "    En cas de présence dans le catalogue du couple (source, fichier) (cas d'un catalogue déjà effectué)\n",
    "    \n",
    "        . mise à jour de l'instance par ajout de l'événement (référencement ko) \n",
    "\n",
    "\n",
    "- Gestion d'un journal\n",
    "\n",
    "    Début de traitement :\n",
    "    \n",
    "        . Ecriture ligne :\n",
    "        \n",
    "            - références du traitement\n",
    "            - répertoire indiqué par l'utilisateur\n",
    "            - répertoire de copie (lieu de stockage de la base de données)\n",
    "            \n",
    "    Pour chaque copie\n",
    "    \n",
    "        . Ecriture ligne : \n",
    "        \n",
    "            - chemin du répertoire origine\n",
    "            - nom du fichier origine\n",
    "            - nom fichier sauvegardé (après gestion de doublon)\n",
    "            \n",
    "\n",
    "Remarques\n",
    "sur les extensions image\n",
    "https://developer.mozilla.org/fr/docs/Web/Media/Formats/Types_des_images\n",
    "    \n",
    "sur les extensions video\n",
    "https://www.reneelab.fr/extension-video.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "from PIL import Image, IptcImagePlugin\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt # pour imgshow\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt #pour timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "#pour les images\n",
    "import PIL.Image\n",
    "import gridfs\n",
    "#pour les images webp\n",
    "#!pip3 install webptools  #webp... et pas web...\n",
    "from webptools import dwebp\n",
    "#pip install opencv-python (pour cv2)\n",
    "#pour les vidéos\n",
    "import cv2\n",
    "import subprocess\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le code de récupération des fichiers images et référencement dans la base mongodb prjph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des fonctions de lecture du catalogue et d'insertion dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getexif(parm_monfichier):\n",
    "    \"\"\"\n",
    "        Fonction de recherche des métadonnées exif des images  -  see https://www.exiv2.org/tags.html pour les définitions\n",
    "        avec en plus un thumbnail\n",
    "        Retourne un dictionnaire\n",
    "        Problème de getexif sur une image de type gif\n",
    "        => solution mep : exception et sortie dictionnaire indiquant pbl\n",
    "                          retrait des types \".gif\" de la liste des types (extensions)\n",
    "        Problème PIL.Image.open sur un fichier m6c8282f3.jpg (dans un répertoire ...HTC_121212.bookmark_thumb1)\n",
    "        => solution mep : exception et sortie dico avec pbl\n",
    "    \"\"\"\n",
    "    bool_img_ok=True\n",
    "    bool_dict_exif_ok=True\n",
    "    try:\n",
    "        img = PIL.Image.open(parm_monfichier)\n",
    "    except:\n",
    "        bool_img_ok=False\n",
    "        bool_dict_exif_ok=False\n",
    "        msg_err = \"Problème ouverture PIL.Image.open\"\n",
    "        \n",
    "    #données exif\n",
    "    if bool_img_ok:\n",
    "        try:\n",
    "            dict_exif = img._getexif()\n",
    "        except:\n",
    "            bool_dict_exif_ok=False\n",
    "            msg_err = \"Données exif non récupérées - problème de format de fichier (gif par exemple) ?\"\n",
    "        \n",
    "    if bool_dict_exif_ok:\n",
    "        #initialisation de la liste des données à supprimer (pas directement sinon pbl de taille de dico qui varie...)\n",
    "        listpop=[]\n",
    "        try:\n",
    "            for k,v in dict_exif.items():\n",
    "                #conversion du type PIL.TiffImagePlugin.IFDRational en string avec ajout du liellé IFDRational\n",
    "                if type(v)==PIL.TiffImagePlugin.IFDRational:\n",
    "                    dict_exif[k]='IFDRational '+str(v)\n",
    "                #et gestion de 42034 (valeur de type tuple avec données Tiff, transformée en string)\n",
    "                if k == 42034: #éventuellement à remplacer par un test sur type tuple s'il y en a d'autres\n",
    "                    dict_exif[k]=str(v)\n",
    "                #je retire les données bytes de plus de 12 de long\n",
    "                if type(v) == bytes and len(str(v)) > 12:\n",
    "                    listpop.append(k)\n",
    "\n",
    "            #Suppression des données \n",
    "            for i in range(len(listpop)):\n",
    "                dict_exif.pop(listpop[i])\n",
    "\n",
    "        except:\n",
    "            mytrue=True\n",
    "\n",
    "        #suppression des clés de type dictionnaire\n",
    "        listpop=[]  #initialisation de la liste des données à supprimer (pas directement sinon pbl de taille de dico qui varie...)\n",
    "        try:\n",
    "            for k,v in dict_exif.items():\n",
    "                if type(v)==dict:\n",
    "                    listpop.append(k)\n",
    "            for i in range(len(listpop)):\n",
    "                dict_exif.pop(listpop[i])\n",
    "        except:\n",
    "            mytrue=True\n",
    "\n",
    "        #conversion des clés (elles sont toutes en numériques) en string (si le dictionnaire est renseigné)\n",
    "        if dict_exif != None:\n",
    "            dict_exif = {str(key):value for (key,value) in dict_exif.items()}\n",
    "    \n",
    "    else:\n",
    "        #Cas où dict_exif._getexif ne fonctionne pas (fichiers .gif par exemple) -> restitution d'un dico 'vide'\n",
    "        dict_exif = {\"msg_err\":msg_err}\n",
    "        \n",
    "    #ajout du thumbnail dans le dictionnaire exif\n",
    "    #...\n",
    "    # A VOIR\n",
    "    #...\n",
    "    #size=(100,100)\n",
    "    #imgth=img.copy()\n",
    "    #print(imgth)\n",
    "    #dict_exif['thumbnail']=imgth.thumbnail(size)\n",
    "    #dict_exif['image']=img\n",
    "\n",
    "    return dict_exif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de la fonction fnph_getexif\n",
    "\n",
    "testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\uneimage\"\n",
    "\n",
    "f='JL_091103 019.jpg'\n",
    "#f='test.jpg'\n",
    "#f='Captureph1.jpg'\n",
    "#f='Capturefondbl.JPG'\n",
    "test=fnph_getexif(join(testRepertoire,f))\n",
    "len(test)\n",
    "\n",
    "#for k,v in test.items():\n",
    "#    print('test-->', k,v,type(v),len(str(v)))\n",
    "#    if type(v)==PIL.TiffImagePlugin.IFDRational:\n",
    "#        print('class pil -> conversion en string', str(v))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getiptc(parm_dir, parm_file):\n",
    "    # pip install pillow\n",
    "    #parm_dir=r'C:\\Users\\LENOVO\\Pictures'\n",
    "    #parm_file='Capturenb.JPG'\n",
    "    \"\"\"\n",
    "    Recherche les informations iptc d'une image \n",
    "    Retourne une liste : 1er élément vrai/faux 2ème:iptc (format dico pour mongo) si ok\n",
    "    \"\"\"\n",
    "\n",
    "    #from PIL import Image, IptcImagePlugin\n",
    "\n",
    "\n",
    "    im = Image.open(os.path.join(parm_dir, parm_file))\n",
    "    \n",
    "    iptc = IptcImagePlugin.getiptcinfo(im)\n",
    "\n",
    "    if iptc:\n",
    "        for k, v in iptc.items():\n",
    "            print(\"{} {}\".format(k, repr(v.decode())))\n",
    "        print('debug--> IPTC INFO TROUVEES !!!!!!!!!!!!!!!!!!!!!!', parm_file)\n",
    "        result=[{\"getiptc\":True ,\"iptc\":iptc}]\n",
    "    else:\n",
    "        #print(\"debug--> This image has no iptc info\")\n",
    "        result=[{\"getiptc\":False , \"iptc\":\"no iptc info\"}]\n",
    "        \n",
    "    return(result)\n",
    "    # We can user getter function to get values\n",
    "    # from specific IIM codes\n",
    "    # https://iptc.org/std/photometadata/specification/IPTC-PhotoMetadata\n",
    "    #def get_caption():\n",
    "    #    return iptc.get((2,120)).decode()\n",
    "    #\n",
    "    #print(get_caption())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'getiptc': False, 'iptc': 'no iptc info'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test fnph_getiptc\n",
    "\n",
    "\n",
    "parm_dir=r'C:\\Users\\LENOVO\\Pictures'\n",
    "parm_file='Capturenb.JPG'\n",
    "fnph_getiptc(parm_dir, parm_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getstats_file(parm_mondir, parm_monfichier):\n",
    "    \"\"\"fonction de recherche des données stats de l'image par os.stats\n",
    "       avec restitution des données st_ sous forme de dictionnaire\n",
    "       pour os.stat see https://docs.python.org/2/library/os.html \n",
    "       os.stat(path) perform the equivalent of a stat() system call on the given path. \n",
    "       \n",
    "    The return value is an object whose attributes correspond to the members of the stat structure, namely:\n",
    "        st_mode - protection bits,\n",
    "        st_ino - inode number,\n",
    "        st_dev - device,\n",
    "        st_nlink - number of hard links,\n",
    "        st_uid - user id of owner,\n",
    "        st_gid - group id of owner,\n",
    "        st_size - size of file, in bytes,\n",
    "        st_atime - time of most recent access,\n",
    "        st_mtime - time of most recent content modification,\n",
    "        st_ctime - platform dependent; time of most recent metadata change on Unix, or the time of creation on Windows)\n",
    "\n",
    "    Changed in version 2.3: If stat_float_times() returns True, the time values are floats, measuring seconds. \n",
    "    Fractions of a second may be reported if the system supports that. See stat_float_times() for further discussion.\n",
    "\n",
    "    On some Unix systems (such as Linux), the following attributes may also be available:\n",
    "    st_blocks - number of 512-byte blocks allocated for file\n",
    "    st_blksize - filesystem blocksize for efficient file system I/O\n",
    "    st_rdev - type of device if an inode device\n",
    "    st_flags - user defined flags for file\n",
    "\n",
    "    On other Unix systems (such as FreeBSD), the following attributes may be available (but may be only filled out if root tries to use them):\n",
    "    st_gen - file generation number\n",
    "    st_birthtime - time of file creation\n",
    "\n",
    "    On RISCOS systems, the following attributes are also available:\n",
    "    st_ftype (file type)\n",
    "    st_attrs (attributes)\n",
    "    st_obtype (object type).\n",
    "\n",
    "    Note The exact meaning and resolution of the st_atime, st_mtime, and st_ctime attributes depend on the operating system \n",
    "    and the file system. For example, on Windows systems using the FAT or FAT32 file systems, st_mtime has 2-second resolution,\n",
    "    and st_atime has only 1-day resolution. \n",
    "    See your operating system documentation for details.\n",
    "\n",
    "    For backward compatibility, the return value of stat() is also accessible as a tuple of at least 10 integers giving the most important (and portable) members of the stat structure, in the order st_mode, st_ino, st_dev, st_nlink, st_uid, st_gid, st_size, st_atime, st_mtime, st_ctime. More items may be added at the end by some implementations.\n",
    "    The standard module stat defines functions and constants that are useful for extracting information from a stat structure. (On Windows, some items are filled with dummy values.)\n",
    "    \"\"\"\n",
    "    #print('.............<fnph_getstats_file>..............')\n",
    "\n",
    "    s_obj=os.stat(os.path.join(parm_mondir, parm_monfichier))\n",
    "    mydicoresult = {k:getattr(s_obj,k) for k in dir(s_obj) if k.startswith(\"st_\")}\n",
    "    #print('\\n',parm_monfichier, ':', mydicoresult)\n",
    "    return mydicoresult\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_copy_file(parm_filename, parm_sourcename, parm_destname):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fonction de copie de fichier\n",
    "    retourne un code status et un commentaire\n",
    "    \"\"\"\n",
    "    myfile_source_name         = os.path.join(parm_sourcename, parm_filename)\n",
    "    myfile_destination_name    = os.path.join(parm_destname,   parm_filename)\n",
    "\n",
    "    \n",
    "    if os.path.exists(myfile_destination_name): #ajout du test car shutil semble ne pas recopier (dcreation inchangée) \n",
    "                                                #mais ne renvoie pas d'erreur\n",
    "        status = \"ko\"\n",
    "        comment = \"Existe déjà dans le répertoire \" + myfile_destination_name\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        try: \n",
    "            myfile_destination_created = shutil.copy2(myfile_source_name, myfile_destination_name) \n",
    "            status=\"ok\"\n",
    "            comment=\"File copied successfully.\"\n",
    "            print(\"File copied successfully.\") \n",
    "            print('done - file', myfile_destination_created, 'created.')\n",
    "\n",
    "\n",
    "        # If source and destination are same \n",
    "        except shutil.SameFileError: \n",
    "            status=\"ko\"\n",
    "            comment=\"Source and destination represents the same file.\"\n",
    "            print(\"\\nSource and destination represents the same file.\")\n",
    "            print(\"------\")\n",
    "            print(\"myfile_source_name:\")\n",
    "            print(myfile_source_name)\n",
    "            print(\"myfile_destination_name:\")\n",
    "            print(myfile_destination_name)\n",
    "            print(\"------\")\n",
    "\n",
    "        # If there is any permission issue \n",
    "        except PermissionError: \n",
    "            status=\"ko\"\n",
    "            comment=\"Impossible to write. Permission denied.\"\n",
    "            print(\"Permission denied.\") \n",
    "\n",
    "        # For other errors \n",
    "        except: \n",
    "            status=\"ko\"\n",
    "            comment=\"Error occurred while copying file.\"\n",
    "            print(\"Error occurred while copying file.\") \n",
    "\n",
    "    return[status,comment]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#test def fnph_copy_file\n",
    "import shutil\n",
    "import os\n",
    "parm_fname=\"Captureph123.PNG\"\n",
    "parm_sourcename=r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\test_shutil\"\n",
    "parm_destname=r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\test_shutil\\copies\"\n",
    "\n",
    "#print(fnph_copy_file(parm_fname, parm_sourcename, parm_destname))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_listDirectory_metadata_copy(parm_directory_name, parm_fileExtDico, parm_db, \n",
    "                                     parm_do_copy=False, parm_do_copy_dest_dir_name=\"\"):                                        \n",
    "    \"\"\" \n",
    "        Fonction de recherche la liste des fichiers du répertoire parm_directory_name\n",
    "        \n",
    "        Pour chaque fichier :\n",
    "        - vérifie s'il est déjà présent ou non dans la base\n",
    "        - s'il n'est pas présent dans la base : \n",
    "             recherche les metadonnées \n",
    "        - copie si souhaitée (présente ou non en base - un event 'copy' indiquera en base le statut de la copie)\n",
    "        \n",
    "        Remarques : \n",
    "        \n",
    "        - parm_db est utilisé pour préparer le stockage de l'image par la fonction fnph_getimage\n",
    "        - parm_fileExtDico est la liste des extensions sous forme de dictionnaire {extension, libellé type de fichier}\n",
    "          Ce paramètre permet d'indiquer le type de fichier en clair dans doctype\n",
    "          Le dico est traduit en liste ensuite ici\n",
    "          C'est la liste qui est transmise aux fonctions appelées ici (elles n'ont pas besoin du label)\n",
    "\n",
    "        Retour : la fonction retourne une liste de dictionnaire des données à insérer - un item par fichier\n",
    "                 - avec un indicateur \"already_exist_in_db\" True/False si le fichier existe ou non dans la base\n",
    "    \"\"\"\n",
    "    #Traitement du dico des types\n",
    "    #Création de la liste des types\n",
    "    fileExtList = [ ext for ext,label in parm_fileExtDico.items()]\n",
    "\n",
    "    #pour la date \n",
    "    dnow = datetime.now()\n",
    "    strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "    fieldname = 'event_'+global_unique_id.replace('.','_') #on met un identifiant unique pour tous les fichiers du même traitement\n",
    "   \n",
    "    #initialisations avant la boucle sur les fichiers du répertoire\n",
    "    nb_files=0\n",
    "    listdata=[]\n",
    "    display1_ok=False\n",
    "    #------- pour l'affichage ------------------------------------d\n",
    "    fnph_incremente_GLOBAL_NUM_FLDR()\n",
    "    prct=GLOBAL_NUM_FLDR/(monRepertoire_totalnb_fldrs+1) #+1 pour compter le répertoire racine également traité\n",
    "    percentage = \"{:.0%}\".format(prct) \n",
    "    print('{}/{}[{}]Rép:{}'.format(GLOBAL_NUM_FLDR,monRepertoire_totalnb_fldrs+1,percentage,parm_directory_name))\n",
    "    #------- pour l'affichage ------------------------------------f\n",
    "    \n",
    "    #création de la liste des fichiers du répertoire (pour extraction des métadonnées et svg dans bd)\n",
    "    mylistfile = [myfile for myfile in os.scandir(parm_directory_name) if myfile.is_file()]\n",
    "    lenlistfile=len(mylistfile)                  #pour print uniquement\n",
    "    cpt=0                                        #pour print uniquement\n",
    "\n",
    "    #------------------------------------------------------------------\n",
    "    #Boucle sur les fichiers de la liste pour recherche des metadonnées\n",
    "    #       et préparation de l'enregistrement à insérer dans la base (données + description événement)\n",
    "    #------------------------------------------------------------------\n",
    "    for f in mylistfile: #ATTENTION : LES ELEMENTS DE mylistfile SONT DES NT.ENTRIES (pas des strings)\n",
    "        cpt+=1\n",
    "        fileDict={\"data\":{},\"already_exist_in_db\":True} #le dictionnaire qui va contenir les metadonnées du fichier\n",
    "        f_name=f.name\n",
    "        #print(\"debug-->\", f.name, f_name, type(f))\n",
    "        \n",
    "        #Ajout d'un test sur l'existence du '.' (des fichiers peuvent ne pas avoir d'extension).  \n",
    "        #            \n",
    "        if f_name.find('.')!=-1: #il y a un '.' (donc une extension), le fichier est traité. Sinon on passe au suivant.\n",
    "            f_ext =\".\"+f_name.split('.')[1].lower()\n",
    "            #if (str(os.path.splitext(f)[1])).lower() in fileExtList:    #ajout de .lower() pour être insensible à la casse\n",
    "            if f_ext in fileExtList:    #ajout de .lower() pour être insensible à la casse\n",
    "                #pour affichage sysout ------------d\n",
    "                #--pourcentage\n",
    "                prct=cpt/lenlistfile\n",
    "                percentage = \"{:.2%}\".format(prct)\n",
    "                #--la durée restante :\n",
    "                nb_totalfiles_treated          = fnph_incremente_GLOBAL_NBTOTFILES_TREATED()\n",
    "                duree_restante, hfin_estimated = fnph_duree_restante(start_time, datetime.now(), nb_totalfiles_treated, \n",
    "                                                            monRepertoire_totalnb_files) #nombre surestimé puisque tous types confondus\n",
    "                msgtodisplay1=\"   <lus/inRep:\"+ str(cpt) + \"/\" + str(lenlistfile) + \") \" + \\\n",
    "                              \"[\" + percentage + \"] \" + \\\n",
    "                              \"... Mdata: \" + f_name + \" ---\" + \\\n",
    "                              \" (cumul:\"+ str(nb_totalfiles_treated) +\"/\"+ str(monRepertoire_totalnb_files) + \")\"+ \\\n",
    "                              \"timeleft:\" + str(duree_restante).split('.')[0] + \"/\" + str(hfin_estimated) + \">\"\n",
    "                sys.stdout.write(\"\\r\" + msgtodisplay1)\n",
    "                sys.stdout.flush()\n",
    "                display1_ok=True #pour gestion de l'affichage\n",
    "                #pour affichage sysout ------------f\n",
    "                #----\n",
    "\n",
    "                var_catfile=parm_fileExtDico[f_ext.lower()]\n",
    "                fileDict[\"data\"]['doctype']=var_catfile  #récupération dans le dico du label du type\n",
    "                #chemin d'origine\n",
    "                fileDict[\"data\"]['orgnl_dirname']=parm_directory_name, \n",
    "                #nom du fichier complet original\n",
    "                #fileDict['filename']=f\n",
    "                fileDict[\"data\"]['filename']=f.name            #suite à l'utilisation de scandir\n",
    "                #extension du fichier (en lower case)\n",
    "                #fileDict['extfile']=os.path.splitext(f)[1].lower()\n",
    "                fileDict[\"data\"]['extfile']=f_ext\n",
    "\n",
    "                #Recherche des metadonnées\n",
    "                if not fnph_alreadyexists_in_db(parm_directory_name, f.name):\n",
    "                    #Test de présence dans la base\n",
    "                    #catégorie de fichier (image, vidéo)\n",
    "                    #stats du fichier\n",
    "\n",
    "                    fileDict[\"data\"][\"stats\"]=fnph_getstats_file(parm_directory_name,f)  #récupération de stats : \n",
    "                                                                 #mode, ino, dev, nling, uid, gid, size, atime, mtime, ctime) \n",
    "                    \n",
    "                    # si ctime est négatif (le cas est arrivé), ctime = 0 et ctime_ns = 0\n",
    "                    if \"st_ctime\" in fileDict[\"data\"][\"stats\"]:\n",
    "                        if fileDict[\"data\"][\"stats\"][\"st_ctime\"] < 0:\n",
    "                            var_st_ct_time    = fileDict[\"data\"][\"stats\"][\"st_ctime\"]\n",
    "                            var_st_ct_time_ns = fileDict[\"data\"][\"stats\"][\"st_ctime_ns\"]\n",
    "                            fileDict[\"data\"][\"stats\"][\"st_ctime\"]    = 0\n",
    "                            fileDict[\"data\"][\"stats\"][\"st_ctime_ns\"] = 0\n",
    "                            fileDict[\"data\"][\"stats\"][\"st_ctime_comment\"]    = \"forcé à 0 - ancienne valeur : \" + \\\n",
    "                                                                            str(var_st_ct_time)\n",
    "                            fileDict[\"data\"][\"stats\"][\"st_ctime_ns_comment\"] = \"forcé à 0 - ancienne valeur : \" + \\\n",
    "                                                                            str(var_st_ct_time_ns)\n",
    "                    \n",
    "                    #Metadonnées (images et vidéos)\n",
    "                    #exif\n",
    "                    if var_catfile=='image':  #à voir comment généraliser (pour éviter la valorisation en dur)\n",
    "\n",
    "                        #si image (VOIR SI NECESSAIRE DE TESTER LE TYPE DE FICHIER POUR LES METATDATA EXIF - NOTMT FICHIERS .MOV)\n",
    "                        fileDict[\"data\"]['exif'] =fnph_getexif(os.path.join(parm_directory_name,f.name))  #récupération des métadonnées exif\n",
    "                        #l'image elle même (réduite?) si image (rendu inactif pour l'instant - ralentit pas mal)\n",
    "                       #fileDict['image']=fnph_getimage(parm_directory_name,f, parm_db)      #récup des métadonnées pour stockage de l'image (nécessite la bd)\n",
    "\n",
    "                    #video metadata\n",
    "                    if var_catfile=='video':  #à voir comment généraliser (pour éviter la valorisation en dur)\n",
    "                        fileDict[\"data\"]['vid_ppty']=fnph_get_video_properties(os.path.join(parm_directory_name,f))\n",
    "\n",
    "                    #iptc\n",
    "                    #pour tous les types d'images : recherche des données iptc - annulé pour l'instant (ne fonctionne pas)\n",
    "                    #fileDict['data']['iptc']=fnph_getiptc(parm_directory_name,f)      #récup des données iptc (si existent) (inactif pour l'instant - ralentit)\n",
    "\n",
    "                    #events\n",
    "                    fileDict['data']['events']={fieldname:{'edate':str(dnow),\n",
    "                                                   'ename':'insert' ,\n",
    "                                                   'estatus':'ok'   }}\n",
    "\n",
    "                    #indication de l'existence ou non du fichier dans la bd\n",
    "                    fileDict['already_exist_in_db']=False\n",
    "\n",
    "\n",
    "                    #initialisation de l'item copy_events\n",
    "                    fileDict['data']['copy_events'] = [{\"event_init\":\"initialisation copy_events \"+ str(datetime.now())}]\n",
    "\n",
    "\n",
    "                else:\n",
    "                    #indication de l'existence ou non du fichier dans la bd\n",
    "                    fileDict['already_exist_in_db']=True\n",
    "\n",
    "                    #initialisation de l'item copy_events\n",
    "                    fileDict['data']['copy_events']=[]\n",
    "\n",
    "\n",
    "\n",
    "                #copie--------------------------------------------------------------------------\n",
    "                copy_event_to_add              = {}           #dictionnaire à ajouter à l'item copy_events\n",
    "                copy_event_to_add[\"copy_id\"  ] = global_unique_id.replace('.','_')\n",
    "                copy_event_to_add[\"copy_date\"] = str(datetime.now())\n",
    "\n",
    "                if parm_do_copy: #copie effectuée si demandée (que le fichier existe ou non dans la base)\n",
    "\n",
    "                    #---------------------------------------------------------------\n",
    "                    copy_status_comment = fnph_copy_file(f.name, parm_directory_name, parm_do_copy_dest_dir_name)\n",
    "                    #---------------------------------------------------------------\n",
    "                    copy_event_to_add[\"copy_source\" ] = os.path.join(parm_directory_name        , f.name)\n",
    "                    copy_event_to_add[\"copy_dest\"   ] = os.path.join(parm_do_copy_dest_dir_name , f.name)\n",
    "                    copy_event_to_add[\"copy_status\" ] = copy_status_comment[0]\n",
    "                    copy_event_to_add[\"copy_comment\"] = copy_status_comment[1]\n",
    "\n",
    "                else:\n",
    "                    copy_event_to_add[\"status\"]=\"na\"\n",
    "                    copy_event_to_add[\"copy_comment\"] = \"copy not asked\"\n",
    "\n",
    "                fileDict['data']['copy_events'].append(copy_event_to_add)    \n",
    "                #Append des données du fichier dans la liste\n",
    "                listdata.append(fileDict)\n",
    "                nb_files+=1\n",
    "\n",
    "            #else: #le type de fichier n'est pas dans la liste ...not in FileExtList\n",
    "        #else: #le type de fichier n'a pas d'extension ...find('.')=1\n",
    "        \n",
    "    #Affichage du nombre de fichiers trouvés\n",
    "    if display1_ok: #pour passer à la ligne après le dernier sys.std (display1) s'il y en a eu\n",
    "        msglibre=\"\" #se place en fin de ligne\n",
    "        print(msglibre)\n",
    "        \n",
    "    return listdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test de la fonction fnph_listDirectory (nécessite fnph...)\n",
    "\n",
    "strtimestamp = str(datetime.timestamp(datetime.now()))\n",
    "global_unique_id = strtimestamp\n",
    "\n",
    "#connection au serveur mongodb 27017, base test\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "mycollection = mydb[\"test_documents\"]\n",
    "\n",
    "#ou encore mycollection = client.prjph_catalogue.test_documents\n",
    "test_dir=r'C:\\Users\\LENOVO\\Pictures'\n",
    "#il faut maintenant un dictionnaire\n",
    "test_type={'.jpg':'image','.png':'image'}\n",
    "\n",
    "test=fnph_listDirectory(test_dir, test_type, mydb)                                        \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de recherche de présence de document dans la base\n",
    "def fnph_alreadyexists_in_db(parm_dirname, parm_filename):\n",
    "    \"\"\"\n",
    "    retourne un booléen\n",
    "    \"\"\"\n",
    "\n",
    "    f=parm_filename\n",
    "    if mycollection.count_documents({\"orgnl_dirname\":parm_dirname,\"filename\":parm_filename}, limit=1):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'incrémentation de la variable globale global_num_fldr\n",
    "def fnph_incremente_GLOBAL_NUM_FLDR():\n",
    "    \"\"\"\n",
    "    incrémente la variable global_num_fldr qui donne le numéro d'ordre du répertoire traité\n",
    "    \"\"\"\n",
    "    global GLOBAL_NUM_FLDR\n",
    "    GLOBAL_NUM_FLDR = GLOBAL_NUM_FLDR + 1\n",
    "    return(GLOBAL_NUM_FLDR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'incrémentation de la variable globale global_nbtotfiles_treated\n",
    "def fnph_incremente_GLOBAL_NBTOTFILES_TREATED():\n",
    "    \"\"\"\n",
    "    incrémente la variable global_num_fldr qui donne le numéro d'ordre du répertoire traité\n",
    "    \"\"\"\n",
    "    global GLOBAL_NBTOTFILES_TREATED\n",
    "    GLOBAL_NBTOTFILES_TREATED = GLOBAL_NBTOTFILES_TREATED + 1\n",
    "    return(GLOBAL_NBTOTFILES_TREATED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_duree_restante(parm_timestart, parm_timenow, parm_nb_treated, parm_nb_tot):\n",
    "    \"\"\"\n",
    "    calcul de la durée restante estimée après traitement de parm_nb_treated éléments sur une durée\n",
    "    donnée par parm_timenow - parm_timestart\n",
    "    Retour : la durée restante et l'heure estimée de fin (parm_timenow + duree_restante)\n",
    "    \"\"\"\n",
    "    timepast           = parm_timenow - parm_timestart\n",
    "    timepast_per_file  = timepast/parm_nb_treated\n",
    "    nb_files_remaining = parm_nb_tot - parm_nb_treated\n",
    "    duree_restante = nb_files_remaining * (timepast_per_file + dt.timedelta(seconds=0.055)) #ajout de 0.055s par file\n",
    "                                                                                             # pour la partie insert/update\n",
    "\n",
    "    time_fin           = parm_timenow + duree_restante \n",
    "    return(duree_restante, str(time_fin.hour)+\":\"+str(time_fin.minute)+\":\"+str(time_fin.second)) #à afficher avec str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:01:00/19:13:26'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST fnph_duree_restante\n",
    "GLOBAL_NBTOTFILES_TREATED = 0\n",
    "test_monRepertoire_totalnb_files = 2 #monRepertoire_totalnb_files\n",
    "\n",
    "test_dnow       = datetime.now()\n",
    "test_start_time = test_dnow.replace(minute=test_dnow.minute-1) # moins 1 minute\n",
    "\n",
    "test_nbtotfiles_treated = fnph_incremente_GLOBAL_NBTOTFILES_TREATED()\n",
    "duree_restante, hfin_estimated = fnph_duree_restante(test_start_time, \n",
    "                                     test_dnow,\n",
    "                                     test_nbtotfiles_treated, \n",
    "                                     test_monRepertoire_totalnb_files) #nombre surestimé puisque tous types confondus\n",
    "\n",
    "str(duree_restante).split('.')[0] + \"/\" + str(hfin_estimated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_cat_filesofonedirectory_majdb(parm_monRepertoire, parm_dicotypes, \n",
    "                                       parm_mydb, parm_do_copy=False, parm_do_copy_dest_dir_name=\"\"):\n",
    "    \"\"\"\n",
    "    fonction de recherche des fichiers de type parm_types dans le répertoire parm_monRepertoire\n",
    "    (via la fonction fnph_listDirectory_metadata_copy)\n",
    "    avec récupération des metadonnées (exif, ...)\n",
    "    et insertion du fichier et des metadonnées dans la bd si non déjà présent\n",
    "    et retourne le nombre d'insertions effectuées, et le nombre de mise à jour\n",
    "    (ajout de parm_mydb pour l'appel à fnph_listDirectory_metadata_copy pour l'appel à fnph_getimage)\n",
    "    \n",
    "    remarque : parm_types est un dictionnaire et uniquement passé aux fonctions appelées\n",
    "    \"\"\"\n",
    "    \n",
    "    #print('debug-->........<fnph_cat_filesofonedirectory_majdb>..............'+str(datetime.now()))\n",
    "\n",
    "    nb_insert=0\n",
    "    nb_update=0\n",
    "    display2_ok=False #pour gestion de l'affichage\n",
    "    #on peut ajouter ici les stats par catégorie image/vidéo avec mylist[i][\"data\"]['cat_img']\n",
    "    \n",
    "    #1-------------------------------------\n",
    "    #Recherche des données à enregistrer dans la base pour chaque fichier dans parm_monRepertoire -> mylist\n",
    "    mylist = fnph_listDirectory_metadata_copy(parm_monRepertoire, parm_dicotypes, parm_mydb,\n",
    "                                              parm_do_copy, parm_do_copy_dest_dir_name)\n",
    "    \n",
    "    #2-------------------------------------\n",
    "    #Ecriture de la liste des éléments dans la bd, élément par élément avec test de présence\n",
    "    #for i in tqdm.tqdm(range(len(mylist))):    #avec affichage de la barre de progression\n",
    "    nb_files_in_rep=len(mylist) #pour l'affichage et éviter les calculs redondants (va plus vite ?)\n",
    "    for i in range(nb_files_in_rep):\n",
    "        test_dirname  = mylist[i][\"data\"][\"orgnl_dirname\"]\n",
    "        test_filename = mylist[i][\"data\"][\"filename\"]\n",
    "\n",
    "        #pour l'affichage-----sysout sur la même ligne pour donner une vision de l'avancement-------------d\n",
    "        prct=(i+1)/nb_files_in_rep\n",
    "        percentage = \"{:.2%}\".format(prct)\n",
    "\n",
    "        msgtodisplay2=\"\\r\" + \"   <indb/toPut:\" + str(i+1) + \"/\" + str(len(mylist)) + \")\" + \\\n",
    "                         \"[\" + percentage + \"] ... InsUp: \" + \\\n",
    "                          test_filename + \" \" + \\\n",
    "                         \"---\" + \">\"\n",
    "        sys.stdout.write(\"\\r\" + msgtodisplay2)\n",
    "        sys.stdout.flush()\n",
    "        display2_ok=True #pour gestion de l'affichage\n",
    "        #print(msgtodisplay2)\n",
    "        #pour l'affichage---------------------------------------------------------------------------------f\n",
    "        \n",
    "        #----------------------------------------------------------------------------------------\n",
    "\n",
    "        #test de présence dans la base\n",
    "        if mylist[i][\"already_exist_in_db\"]:\n",
    "            #UPDATE\n",
    "            ##### mise à jour par ajout de champ dans un champ existant (utilisation de .)\n",
    "            dnow = datetime.now()\n",
    "            #strnow = str(dnow.year)[:2]+str(dnow.month)+str(dnow.day)+str(dnow.hour)+str(dnow.minute)+str(dnow.second)+'_'+str(dnow.microsecond)\n",
    "            strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "           #fieldname = 'events.event_'+str(strtimestamp)\n",
    "            fieldname = 'events.event_'+global_unique_id.replace('.','_') #on met un identifiant unique pour tous les fichiers du même traitement\n",
    "               \n",
    "            #set pour ajouter/màj un champ de type objet, push pour ajouter un élément dans un item de type liste\"\n",
    "            result = mycollection.update_many( \n",
    "                                                 {\"orgnl_dirname\":test_dirname,\"filename\":test_filename}, \n",
    "                                                 {'$set' :{fieldname    :{'edate':str(dnow),\n",
    "                                                                         'ename':'insert ko',\n",
    "                                                                         'estatus':'already exists',\n",
    "                                                                         }\n",
    "                                                          },\n",
    "                                                  '$push':{\"copy_events\":{\"$each\":mylist[i][\"data\"][\"copy_events\"]}}\n",
    "                                                  }\n",
    "                                             )\n",
    "            \n",
    "            nb_update+=1\n",
    "            \n",
    "        else:\n",
    "            #INSERT\n",
    "            #print('debug--><fnph_cat_f...> n''existe pas -> insertion de mylist[',i,'] --------', str(mylist[i])) #[0:40], '.........')\n",
    "            mycollection.insert_one(mylist[i][\"data\"])\n",
    "            nb_insert+=1\n",
    "            \n",
    "    \n",
    "    if display2_ok:\n",
    "        msglibre=\"\"\n",
    "        print(msglibre) #ce print pour passer à la ligne - s'ajoute en fin de ligne\n",
    "    return [nb_insert,nb_update]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test de mise à jour avec push (ajout d'élément dans un array)\n",
    "test_dirname=\"C:\\\\Users\\\\LENOVO\\\\Documents\\\\Projets\\\\Prj_photos\\\\Prjph_repertoire_test\\\\diximages\\\\sr_deuximages\"\n",
    "test_dirname=\"C:\\\\Users\\\\LENOVO\\\\Documents\\\\Projets\\\\Prj_photos\\\\Prjph_repertoire_test\\\\diximages\"\n",
    "test_filename=\"Capturefondnb.JPG\"\n",
    "\n",
    "#mylist[i][\"data\"][\"copy_events\"]\n",
    "\n",
    "#result = mycollection.update_many( \n",
    "#                                                 {\"orgnl_dirname\":test_dirname,\"filename\":test_filename}, \n",
    "#                                                 {\"$push\"        :{\"copy_events\":[{\"nouveau\":8}]}        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction récursive de traitement d'un répertoire\n",
    "\n",
    "def fnph_traitementrep(parm_rep, parm_dicotypes, parm_mydb, parm_df_log_cols, \n",
    "                       parm_do_copy=False, parm_do_copy_dest_dir_name=\"\"):\n",
    "    \"\"\"fonction récursive de traitement d'un répertoire et de ses sous-répertoires\n",
    "        par lecture des sous-répertoires\n",
    "        et pour chacun, appel récursif de la fonction pour effectuer le même traitement\n",
    "        puis traitement des fichiers du répertoire courant\n",
    "        parm_df_log_cols sert à récupérer la structure du df historique (pour simplifier les éventuelles modif de structure)\n",
    "        retourne \n",
    "        - le nombre d'insert et d'update\n",
    "        - le nombre d'update\n",
    "        - le nombre de répertoires explorés\n",
    "        - le df_log (!)\n",
    "        (ajout de parm_mydb pour appel à fnph_getimage appelée dans les fonctions appelées)\n",
    "        \n",
    "        remarque : parm_dicotypes est un dictionnaire, et il est juste transmis aux fonctions appelées\n",
    "    \"\"\"\n",
    "    #from os import listdir\n",
    "    #from os.path import isfile, join, isdir\n",
    "\n",
    "    #print('.............<fnph_traitementrep>..............')\n",
    "    #print('Répertoire exploré :', parm_rep)\n",
    "    \n",
    "    #Initialisation des compteurs d'insertion et mise à jour\n",
    "    nbtot_insert = 0\n",
    "    nbtot_update = 0\n",
    "    #Initialisation des compteurs de répertoires explorés et du dataframe historique\n",
    "    local_log_nb_rep = 0\n",
    "    local_df_log     = pd.DataFrame(columns=parm_df_log_cols) \n",
    "\n",
    "    #Gestion de reprise : \n",
    "    #Test si répertoire déjà traité (Code_statut_terminé = True ?)\n",
    "    # Si oui, fin de traitement\n",
    "    # Si non, \n",
    "    #       insertion d'un enregistrement dans la bd pour suivi des traitements - Repertoire xxx -début trt\n",
    "    #             Répertoire         : nom répertoire\n",
    "    #             Statut             : début de traitement\n",
    "    #             Code_statut_terminé: False\n",
    "    #             Date               : datetime.now()\n",
    "    #       et suite du traitement\n",
    "    \n",
    "    #----------------------------------------------\n",
    "    #1)recherche des répertoires (sous-répertoires)\n",
    "    #----------------------------------------------\n",
    "    liste_repertoires = [r for r in listdir(parm_rep) if isdir(join(parm_rep, r))]\n",
    "    #possible ici de remplacer par scandir... à voir\n",
    "    \n",
    "    #Traitement des répertoires (appel récursif) pour traitement des fichiers et des (sous-)répertoires\n",
    "    #for onerep in tqdm.tqdm(liste_repertoires):   #avec affichage de la barre de progression\n",
    "    for onerep in liste_repertoires:\n",
    "        #pour chaque sous-rep trouvé :\n",
    "        local_log_nb_rep+=1 #incrémentation du nombre de répertoires traités à chaque répertoire traité\n",
    "        \n",
    "        #appel récursif --------------------------------------------------------------------------------\n",
    "        list_rep_nb = fnph_traitementrep(join(parm_rep,onerep), parm_dicotypes, parm_mydb, parm_df_log_cols, \n",
    "                                         parm_do_copy, parm_do_copy_dest_dir_name)\n",
    "        #appel récursif --------------------------------------------------------------------------------\n",
    "        if type(list_rep_nb)==list:\n",
    "            nbtot_insert    +=list_rep_nb[0]\n",
    "            nbtot_update    +=list_rep_nb[1]\n",
    "            local_log_nb_rep+=list_rep_nb[2]\n",
    "            local_df_log     =local_df_log.append(list_rep_nb[3])\n",
    "\n",
    "    #----------------------------------------------\n",
    "    #2)traitement des fichiers du répertoire courant avec insert et/ou update dans la fonction fnph_cat_filesononedirectory()\n",
    "    #----------------------------------------------\n",
    "    #appel à la fonction de traitement des fichiers du répertoire \n",
    "    # (recherche des fichiers dans le répertoire, de leurs metadonnées et mise à jour de la bd)\n",
    "    loc_debut_time=datetime.now() #pour avoir une idée de la durée de l'appel (insertion/update)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    list_files_nb = fnph_cat_filesofonedirectory_majdb(parm_rep, parm_dicotypes, parm_mydb, \n",
    "                                                       parm_do_copy, parm_do_copy_dest_dir_name)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    loc_fin_time  =datetime.now() #\n",
    "    loc_duree = loc_fin_time - loc_debut_time\n",
    "    if type(list_files_nb)==list:\n",
    "        nbtot_insert+=list_files_nb[0]\n",
    "        nbtot_update+=list_files_nb[1]\n",
    "        #ce print pour aller à la ligne après les sys.stdout.write dans fnph_cat_filesofonedirectory_majdb\n",
    "        #print(\" <... (put in bd:\" + str(list_files_nb[0]+list_files_nb[1]) + \")>\") \n",
    "        #sys.stdout.write(\"\\r\" + \"<sys3\" +\n",
    "        #           str(list_files_nb[0]+list_files_nb[1]) + \n",
    "        #           \"/\" + str(nbtot_insert+nbtot_update) + \" files\" +\n",
    "        #           #\"-d:\"+str(loc_debut_time) + \"-f:\"+str(loc_fin_time) +\n",
    "        #           \" - durée : \" + str(loc_duree).split('.')[0] + \"finsys3>\" ) \n",
    "        #sys.stdout.flush()\n",
    "        #\n",
    "    #ajout (append) du répertoire traité 'parm_rep' dans le df historique\n",
    "    local_df_log     = local_df_log.append({ 'unique_id'        :  global_unique_id,\n",
    "                                             'time'              : str(datetime.now()),\n",
    "                                             'rep_explored'      : parm_rep,\n",
    "                                             'nb_sous_rep'       : len(liste_repertoires), \n",
    "                                             'nb_of_files'       : list_files_nb[0]+list_files_nb[1],\n",
    "                                             'nb_of_files_cumul' : nbtot_insert+nbtot_update,\n",
    "                                             'comment'           : \"\"}, \n",
    "                                             ignore_index=True) \n",
    "    \n",
    "    #Gestion de reprise : insertion d'un enregistrement dans la bd pour suivi des traitements - Repertoire xxx -fin trt\n",
    "    # Répertoire : nom répertoire\n",
    "    # Statut     : Traitement terminé\n",
    "    # Code_statut_terminé: True\n",
    "    # Date       : datetime.now()\n",
    "    # nb_sous_rep: len(liste_repertoires), \n",
    "    # nb_of_files: list_files_nb[0]+list_files_nb[1]\n",
    "\n",
    "    \n",
    "    return [nbtot_insert, nbtot_update, local_log_nb_rep, local_df_log]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>rep_explored</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-24 19:12:26.089543</td>\n",
       "      <td>a path</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time rep_explored comment\n",
       "0  2020-10-24 19:12:26.089543       a path    test"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test appel fnph_traitementrep\n",
    "\n",
    "start_time=datetime.now()\n",
    "GLOBAL_NUM_FLDR=0\n",
    "GLOBAL_NBTOTFILES_TREATED=0\n",
    "strtimestamp = str(datetime.timestamp(datetime.now()))\n",
    "global_unique_id = strtimestamp\n",
    "monRepertoire_totalnb_fldrs=10 #forcé pour test\n",
    "monRepertoire_totalnb_files=10 #forcé pour test\n",
    "\n",
    "#connection au serveur mongodb 27017, base test\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "mycollection = mydb[\"test_documents\"]\n",
    "#ou encore mycollection = client.prjph_catalogue.test_documents\n",
    "\n",
    "#testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\diximages\"\n",
    "#testRepertoire = '\\\\\\\\DESKTOP-AQNKR8B\\\\Pictures'\n",
    "testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\uneimage\"\n",
    "\n",
    "mydico_types={'.JPG':'image','.jpg':'image'}\n",
    "mynbrep=0\n",
    "mydflog=pd.DataFrame([{'time':str(datetime.now()),'rep_explored':'a path', 'comment':'test'}])\n",
    "\n",
    "#appel\n",
    "#fnph_traitementrep(testRepertoire, mydico_types, mydb, mydflog.columns)\n",
    "\n",
    "\n",
    "mydflog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getimage(parm_path, parm_file, parm_db):\n",
    "    \"\"\"\n",
    "    Cette fonction convertit un fichier image en une donnée stockable dans mongodb\n",
    "    Elle restitue les métadonnées à stocker dans la base mongo (passée en paramètres pour le stockage intermédaire je suppose)\n",
    "    \"\"\"\n",
    "    #print('.............<fnph_getimage>..............')\n",
    "\n",
    "    \n",
    "    #from pymongo import MongoClient\n",
    "    #import gridfs\n",
    "    #pip install opencv-python (pour cv2)\n",
    "    #import cv2\n",
    "    #import os\n",
    "    \n",
    "    pathfile=os.path.join(parm_path, parm_file)\n",
    "\n",
    "    # access our image collection\n",
    "    #client = MongoClient('localhost', 27017)\n",
    "    #db = client['prjph_catalogue']\n",
    "    #testCollection = db['test_documents']\n",
    "    fs = gridfs.GridFS(parm_db) #donc envoyer client['prjph_catalogue'] dans parm_db\n",
    "\n",
    "    # read the image and convert it to RGB\n",
    "    myfile=pathfile\n",
    "\n",
    "    image = cv2.imread(myfile)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # convert ndarray to string\n",
    "    imageString = image.tostring()\n",
    "\n",
    "    # store the image (stockage intermédiaire quelquepart dans la base avant insertion des métadonnées)\n",
    "    imageID = fs.put(imageString, encoding='utf-8')\n",
    "\n",
    "    # create our image meta data \n",
    "    meta = {\n",
    "        'name': parm_file,\n",
    "        'images': [\n",
    "            {\n",
    "                'imageID': imageID,\n",
    "                'shape': image.shape,\n",
    "                'dtype': str(image.dtype)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_retreive_image(parm_filename, parm_mydb, parm_mycollection):\n",
    "    #see https://stackoverflow.com/questions/49493493/python-store-cv-image-in-mongodb-gridfs\n",
    "    \"\"\"\n",
    "    Fonction retreive image dans mongo pour affichage de l'image stockée avec la fonction getimages\n",
    "    \"\"\"\n",
    "    \n",
    "    #Retreive\n",
    "    #import numpy as np\n",
    "    #import gridfs\n",
    "    #from matplotlib import pyplot as plt\n",
    "\n",
    "    #base\n",
    "    #client = pymongo.MongoClient('localhost',27017)\n",
    "    #mydb = client[\"prjph_catalogue\"]\n",
    "    #mycollection = mydb[\"test_documents\"]\n",
    "\n",
    "    #nom de l'image à récupérer (valeur du champ 'name')\n",
    "    #parm_name = parm_filename\n",
    "\n",
    "    # get the image meta data\n",
    "    image = parm_mycollection.find_one({'name': parm_filename})['images'][0]\n",
    "\n",
    "    # get the image from gridfs\n",
    "    fs = gridfs.GridFS(mydb) #donc envoyer client['prjph_catalogue'] dans parm_db\n",
    "\n",
    "    gOut = fs.get(image['imageID'])\n",
    "\n",
    "    # convert bytes to ndarray\n",
    "    img = np.frombuffer(gOut.read(), dtype=np.uint8)\n",
    "\n",
    "    # reshape to match the image size\n",
    "    img = np.reshape(img, image['shape'])\n",
    "\n",
    "    #Affichage\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test fnph_retreive_image\n",
    "\n",
    "#filename='Capturenb.JPG'\n",
    "\n",
    "#testimage=fnph_retreive_image(filename, mydb, mycollection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de calcul du nombre et de la taille totale des fichiers catalgués dans la base\n",
    "\n",
    "def fnph_clc_nb_st_size_tot(parm_collection):\n",
    "    \"\"\"\n",
    "    Fonction de calcul du nombre et de la taille totale des fichiers catalgués dans la base\n",
    "    retourne une liste de deux éléments : taille, nombre\n",
    "    \"\"\"\n",
    "    #Requête aggrégation\n",
    "    totalSize = parm_collection.aggregate(\n",
    "       [\n",
    "         {\n",
    "           \"$group\":\n",
    "             {\n",
    "               \"_id\"        : \"\",\n",
    "               \"totalSize\"  : { \"$sum\": \"$stats.st_size\" },\n",
    "               \"count\"      : { \"$sum\": 1 }\n",
    "             }\n",
    "         }\n",
    "       ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    reslist=list(totalSize)[0]\n",
    "    result=[reslist['totalSize'], reslist['count']]\n",
    "    \n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test appel fonction fnph_clc_nb_st_size_tot\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "mycollection = mydb[\"test_documents\"]\n",
    "\n",
    "#fnph_clc_nb_st_size_tot(mycollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-5b658806237e>:30: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  imageString = image.tostring()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Capturenb.JPG',\n",
       " 'images': [{'imageID': ObjectId('5f94607a574d3385f4286b6f'),\n",
       "   'shape': (482, 540, 3),\n",
       "   'dtype': 'uint8'}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test fnph_getimage\n",
    "\n",
    "testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\diximages\"\n",
    "testfile='Captureph1.jpg'\n",
    "testfile='Capturenb.JPG'\n",
    "\n",
    "testmeta=fnph_getimage(testRepertoire,testfile, mydb)\n",
    "\n",
    "testmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_get_video_properties(filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Récupère les metadata du fichier avec la bibliothèque 'hachoir'\n",
    "    \"\"\"\n",
    "    #!pip3 install hachoir\n",
    "    #import subprocess\n",
    "    \n",
    "    getresult_ok=True\n",
    "    try:\n",
    "        result = subprocess.Popen(['hachoir-metadata', filename, '--raw', '--level=3'],\n",
    "            stdout = subprocess.PIPE, stderr = subprocess.STDOUT)\n",
    "    except:\n",
    "        msg_err=\"ERREUR result=subprocess... dans fnph_get_video_properties pour le fichier \" + filename\n",
    "        getresult_ok=False\n",
    "    \n",
    "    if getresult_ok:\n",
    "        results = result.stdout.read().decode('utf-8').split('\\r\\n')\n",
    "\n",
    "        properties = {}\n",
    "        #formatage des données duration, width, height\n",
    "        for item in results:\n",
    "\n",
    "            if item.startswith('- duration: '):\n",
    "                duration = item.lstrip('- duration: ')\n",
    "                if '.' in duration:\n",
    "                    #t = datetime.datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S.%f')\n",
    "                    t = datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S.%f')\n",
    "                else:\n",
    "                    #t = datetime.datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S')\n",
    "                    t = datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S')\n",
    "                seconds = (t.microsecond / 1e6) + t.second + (t.minute * 60) + (t.hour * 3600)\n",
    "                properties['duration'] = round(seconds)\n",
    "\n",
    "            if item.startswith('- width: '):\n",
    "                properties['width'] = int(item.lstrip('- width: '))\n",
    "\n",
    "            if item.startswith('- height: '):\n",
    "                properties['height'] = int(item.lstrip('- height: '))\n",
    "\n",
    "        #ajout de toutes les données (yc duration, width, height)\n",
    "        #properties['metadata_all']=results                                 <<<<<<<<<<<<< A TESTER\n",
    "        \n",
    "    else:\n",
    "        properties={'msg_err':msg_err}\n",
    "        \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 617 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'duration': 12, 'width': 1920, 'height': 1080}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#test appel fnph_get_video_properties\n",
    "monRepertoire = r\"C:\\Users\\LENOVO\\Videos\\Captures\"\n",
    "monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\Fichiers_MOV\"\n",
    "monFichier = \"IMG_0578.MOV\"\n",
    "\n",
    "myfile=os.path.join(monRepertoire,monFichier)\n",
    "fnph_get_video_properties(myfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_startandend_ajout_evnmtppl_mongodb(parm_state,        parm_titretraitement, parm_dir,   parm_types, \n",
    "                                            parm_mycollection, parm_tailletot,       parm_nbtot, parm_nb_insupd,\n",
    "                                            parm_nb_rep,       parm_duration,\n",
    "                                            parm_do_copy,      parm_do_copy_dest_dir_name\n",
    "                                           ):\n",
    "\n",
    "    \"\"\"\n",
    "    parm_state indique s'il s'agit du début du traitement (\"début\")\n",
    "        alors on regarde s'il faut écrire eventgnl_000000000\n",
    "    ou s'il s'agit de la fin de traitement (\"fin\") \n",
    "        alors on écrit les stats\n",
    "    fonction d'écriture dans la base mongodb de l'événement 'traitement'\n",
    "    on écrit un événement avec les éléments suivants\n",
    "    - identifiant événement\n",
    "    - date heure\n",
    "    - nom du traitement\n",
    "    - nom du répertoire exploré\n",
    "    - nombre de fichiers traités\n",
    "    - (nombre de fichiers image)\n",
    "    - (nombre de fichiers vidéo)\n",
    "    - nombre d'insersions\n",
    "    - nombre de mises à jour\n",
    "    - volume après traitement (cumul des tailles de fichiers)\n",
    "    - nombre total de documents \n",
    "    \"\"\"\n",
    "    \n",
    "    #print('.............<fnph_startandend_ajout_evnmtppl_mongodb>..............')\n",
    "\n",
    "    #Création des variables\n",
    "    dnow = datetime.now()\n",
    "    strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "    dnow=str(dnow)\n",
    "\n",
    "    #Création du dico\n",
    "\n",
    "    #on créée la donnée eventppl si elle n'existe pas déjà (cas de création de la base)\n",
    "    if parm_state==\"début\":\n",
    "        if not mycollection.count_documents({\"eventgnls.eventgnl_000000000.epname\":\"création\"}, limit=1):\n",
    "            mycollection.insert_one({\"eventgnls\":{\"eventgnl_000000000\":{\"epdate\":str(dnow),\"epname\":\"création\"}}})\n",
    "\n",
    "    if parm_state==\"fin\":\n",
    "    #Ecriture des données (mise à jour de eventppl - il n'y en a qu'un - par ajout d'un sous-document)   \n",
    "       #fieldname = 'eventgnls.eventgnl_'+str(strtimestamp)\n",
    "        fieldname = 'eventgnls.eventgnl_'+global_unique_id.replace('.','_') #on met l'identifiant unique utilisé \n",
    "                                                                            #pour tous les fichiers du même traitement\n",
    "               \n",
    "        result = mycollection.update_many( \n",
    "                     {\"eventgnls.eventgnl_000000000.epname\":'création'}, #on cherche eventppl renseigné (il n'y en a qu'un)\n",
    "                     {'$set':{fieldname:{'epdate'           :str(dnow),  #ajout des données suivantes\n",
    "                                         'epname'           :parm_titretraitement,\n",
    "                                         'epdir'            :parm_dir,\n",
    "                                         'ep_copy_asked'    :parm_do_copy, \n",
    "                                         'ep_copy_dest'     :parm_do_copy_dest_dir_name,\n",
    "                                         'eptypes'          :parm_types,\n",
    "                                         'epnb_ins'         :parm_nb_insupd[0],\n",
    "                                         'epnb_upd'         :parm_nb_insupd[1],\n",
    "                                         'eptot_size_files' :parm_tailletot,\n",
    "                                         'epnb_files_in_bd' :parm_nbtot,\n",
    "                                         'epnb_rep_explored':parm_nb_rep,\n",
    "                                         'epduration_trtmt' :parm_duration\n",
    "                                         }}} )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getstats_dir(parm_dir):\n",
    "\n",
    "    \"\"\"\n",
    "    Cette fonction renvoie le nombre de fichier et de sous-répertoires sur toute l'arborescence de parm_dir\n",
    "    \"\"\"\n",
    "    nb_files   = 0\n",
    "    nb_folders = 0\n",
    "\n",
    "    for _, dirnames, filenames in os.walk(parm_dir): # _ for 'root' not used here\n",
    "        nb_files   += len(filenames)\n",
    "        nb_folders += len(dirnames)\n",
    "\n",
    "    #print(\"{:,} files, {:,} folders\".format(files, folders))\n",
    "    return [nb_files, nb_folders]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[494, 78]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test fnph_getstats_dir()\n",
    "path=r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\"\n",
    "path=r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\"\n",
    "\n",
    "fnph_getstats_dir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programme principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           global_unique_id: 1603559547.177919 \n",
      "\n",
      "start..................... :  2020-10-24 19:12:27.180919 \n",
      "\n",
      "accès à D:\\A_METTRE_SUR_CD_surDD150418 pour récupérer le nombre de sous-répertoires et de fichiers...\n",
      "...\n",
      "... ok\n",
      "\n",
      "**** Collection            : images_videos ****\n",
      "\n",
      "**** Répertoire            : D:\\A_METTRE_SUR_CD_surDD150418 ****\n",
      "\n",
      "****  nb folders (total)   : 134 ****\n",
      "\n",
      "****  nb files (tous types): 94069 ****\n",
      "\n",
      "remarque : les deux nombres après chaque répertoire correspondent\n",
      "           au nombre de fichiers à la racine du répertoire et celui cumulé avec ceux des sous-répertoires\n",
      "           de type recherché et qui ont été insérés ou mis à jours dans la base\n",
      "\n",
      "1/134[1%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\.Thumbs\n",
      "2/134[1%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\\DVD130501_210811-030213_ok_SurDVD_Peut_etre_supprimé\n",
      "   <lus/inRep:2883/2883) [100.00%] ... Mdata: _SC_9446.JPG --- (cumul:2882/94069)timeleft:4:24:58/23:43:9>4>1>\n",
      "   <indb/toPut:2882/2882)[100.00%] ... InsUp: _SC_9446.JPG --->>->\n",
      "3/134[2%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\\DVD130503_040213\n",
      "   <lus/inRep:894/895) [99.89%] ... Mdata: IMAG3166.jpg --- (cumul:3776/94069)timeleft:7:59:12/3:28:14>13>>\n",
      "   <indb/toPut:894/894)[100.00%] ... InsUp: IMAG3166.jpg --->-->\n",
      "4/134[3%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\\DVD130503_220310-010610\\JL_120619_Sortie_LaVillette_MS_Lucie\n",
      "   <lus/inRep:33/34) [97.06%] ... Mdata: IMAG1051.jpg --- (cumul:3809/94069)timeleft:9:02:08/4:33:58>\n",
      "   <indb/toPut:33/33)[100.00%] ... InsUp: IMAG1051.jpg --->\n",
      "5/134[4%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\\DVD130503_220310-010610\\JL_120621_Fete_Musique\n",
      "   <lus/inRep:14/14) [100.00%] ... Mdata: VIDEO0320.3gp --- (cumul:3822/94069)timeleft:9:07:44/4:39:53>\n",
      "   <indb/toPut:13/13)[100.00%] ... InsUp: VIDEO0320.3gp --->\n",
      "6/134[4%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\\DVD130503_220310-010610\\Part01_ok_surDVD_Peut_etre_supprimé\n",
      "   <lus/inRep:2000/2001) [99.95%] ... Mdata: JL_120303 008.jpg --- (cumul:5822/94069)timeleft:7:22:43/2:59:3>>\n",
      "   <indb/toPut:2000/2000)[100.00%] ... InsUp: JL_120303 008.jpg --->\n",
      "7/134[5%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\\DVD130503_220310-010610\\Part02_en_cours\n",
      "8/134[6%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\\DVD130503_220310-010610\n",
      "   <lus/inRep:16521/16521) [100.00%] ... Mdata: video-2012-06-13-17-34-14.mp4 --- (cumul:22310/94069)timeleft:4:33:34/0:50:38>2>\n",
      "   <indb/toPut:16488/16488)[100.00%] ... InsUp: video-2012-06-13-17-34-14.mp4 --->-->\n",
      "9/134[7%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Photos\n",
      "10/134[7%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Videos\\JL_120619_Spectacle_Lucie_MS\n",
      "   <lus/inRep:3/3) [100.00%] ... Mdata: VIDEO0303.3gp --- (cumul:22312/94069)timeleft:7:18:51/4:27:18>\n",
      "   <indb/toPut:2/2)[100.00%] ... InsUp: VIDEO0303.3gp --->\n",
      "11/134[8%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Videos\n",
      "   <lus/inRep:498/649) [76.73%] ... Mdata: VIDEO0453.3gp --- (cumul:22809/94069)timeleft:7:17:40/4:29:18>7:14:00/4:23:10>"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 126: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e229f7be36f3>\u001b[0m in \u001b[0;36mfnph_traitementrep\u001b[1;34m(parm_rep, parm_dicotypes, parm_mydb, parm_df_log_cols, parm_do_copy, parm_do_copy_dest_dir_name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m#appel récursif --------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         list_rep_nb = fnph_traitementrep(join(parm_rep,onerep), parm_dicotypes, parm_mydb, parm_df_log_cols, \n\u001b[0m\u001b[0;32m     53\u001b[0m                                          parm_do_copy, parm_do_copy_dest_dir_name)\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m#appel récursif --------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e229f7be36f3>\u001b[0m in \u001b[0;36mfnph_traitementrep\u001b[1;34m(parm_rep, parm_dicotypes, parm_mydb, parm_df_log_cols, parm_do_copy, parm_do_copy_dest_dir_name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m#appel récursif --------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         list_rep_nb = fnph_traitementrep(join(parm_rep,onerep), parm_dicotypes, parm_mydb, parm_df_log_cols, \n\u001b[0m\u001b[0;32m     53\u001b[0m                                          parm_do_copy, parm_do_copy_dest_dir_name)\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m#appel récursif --------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e229f7be36f3>\u001b[0m in \u001b[0;36mfnph_traitementrep\u001b[1;34m(parm_rep, parm_dicotypes, parm_mydb, parm_df_log_cols, parm_do_copy, parm_do_copy_dest_dir_name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m#appel récursif --------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         list_rep_nb = fnph_traitementrep(join(parm_rep,onerep), parm_dicotypes, parm_mydb, parm_df_log_cols, \n\u001b[0m\u001b[0;32m     53\u001b[0m                                          parm_do_copy, parm_do_copy_dest_dir_name)\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m#appel récursif --------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e229f7be36f3>\u001b[0m in \u001b[0;36mfnph_traitementrep\u001b[1;34m(parm_rep, parm_dicotypes, parm_mydb, parm_df_log_cols, parm_do_copy, parm_do_copy_dest_dir_name)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mloc_debut_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pour avoir une idée de la durée de l'appel (insertion/update)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m#--------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     list_files_nb = fnph_cat_filesofonedirectory_majdb(parm_rep, parm_dicotypes, parm_mydb, \n\u001b[0m\u001b[0;32m     69\u001b[0m                                                        parm_do_copy, parm_do_copy_dest_dir_name)\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m#--------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-3499ee52be1f>\u001b[0m in \u001b[0;36mfnph_cat_filesofonedirectory_majdb\u001b[1;34m(parm_monRepertoire, parm_dicotypes, parm_mydb, parm_do_copy, parm_do_copy_dest_dir_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#1-------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#Recherche des données à enregistrer dans la base pour chaque fichier dans parm_monRepertoire -> mylist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     mylist = fnph_listDirectory_metadata_copy(parm_monRepertoire, parm_dicotypes, parm_mydb,\n\u001b[0m\u001b[0;32m     24\u001b[0m                                               parm_do_copy, parm_do_copy_dest_dir_name)\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a4e67043cd99>\u001b[0m in \u001b[0;36mfnph_listDirectory_metadata_copy\u001b[1;34m(parm_directory_name, parm_fileExtDico, parm_db, parm_do_copy, parm_do_copy_dest_dir_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m                     \u001b[1;31m#video metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mvar_catfile\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'video'\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#à voir comment généraliser (pour éviter la valorisation en dur)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m                         \u001b[0mfileDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vid_ppty'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfnph_get_video_properties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparm_directory_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                     \u001b[1;31m#iptc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-6557b08d85e7>\u001b[0m in \u001b[0;36mfnph_get_video_properties\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetresult_ok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mproperties\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 126: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Programme principal\n",
    "#Lecture du catalogue de fichier et constitution du dictionnaire des données à insérer dans la base (fnp_listDirectory)\n",
    "#puis écriture dans la base de chaque fichier et de ses données s'il n'est pas déjà présent. Sinon, mise à jour de ses\n",
    "#données (ajout d'un événement).\n",
    "\n",
    "\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "\n",
    "#Répertoire de sauvegarde de l'historique des répertoires explorés\n",
    "parm_df_log_rep = r'C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_log'\n",
    "\n",
    "#Paramètres de connexion\n",
    "#------ Base  -------------------*\n",
    "#connection au serveur mongodb 27017, base test\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "\n",
    "#------ COPIE DES FICHIERS ? -------------*  #0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "#------------------*\n",
    "mydo_copy = False\n",
    "#------------------*\n",
    "mydo_copy_dest_dir_name = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\test_shutil\\copies\"\n",
    "\n",
    "#------ LIBELLE DU TRAITEMENT-------------*  #1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "montitre_traitement=\"Catalogue de fichiers - DD WD - \" #Est systématiquement complété plus bas\n",
    "                                                                             #par monRepertoire\n",
    "#------ COLLECTION -------------------*      #2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "#mycollection_name = \"test_documents\"        #TEST\n",
    "mycollection_name = \"images_videos\"          #PREPROD\n",
    "#------ ---------- -------------------*\n",
    "mycollection = mydb[mycollection_name]\n",
    "#------ REPERTOIRE INITIAL ---------------*  #3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "#.........................................*\n",
    "#REPERTOIRES DE TEST (dans la collection test_documents)\n",
    "#.........................................*\n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\test_shutil\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Pictures\\MyPhotos\"\n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Videos\\Captures\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Pictures\"\n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\diximages\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\MyPhotos\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #SUR LES .MOV UNIQUEMENT 181020 - 00h45 env (durée : qq minutes) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Picosmos\" #nouveaux types d'images : webp\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Svgd_iPhone\" ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\SvgWhatsapp\\iPhone de Patrice iPhone 5S\\Messages\\2019-06-06\\WhatsApp\\Coeur de kid\\Coeur de kid [1]\"\n",
    "#suite plantage sur fichier 08.jpg.png :\n",
    "#monRepertoire = r\"D:\\A_METTRE_SUR_CD_surDD150418\\JL_130101_DCIM_HTC_okbis\\DCIM\\.Thumbs\" #pour 08.jpg.png\"\n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\fichier_plantage\"\n",
    "#monRepertoire = r\"D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\DVD_121231-130118_ok (peut être supprimé)\\JL_130118_DCIM_HTC_part1\\DCIM\"\n",
    "\n",
    "\n",
    "#.........................................*\n",
    "#REPERTOIRES DE PREPROD (dans la collection images_videos)\n",
    "#.........................................*\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\De_DD_Verbatim\" #171020 - 00h33 environ. ko \n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\Nouveau dossier\" #pour résoudre pbl ouverture img=PIL....img\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\De_DD_Verbatim\" #171020 - 01h03 environ. ok (durée : 1h52)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Chiens\" #171020 - 16h00 env (durée : qq secondes)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Ecole\" #171020 - 16h05 env (durée : qq secondes)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #181020 - 00h22 env (durée : ...) ko (manque subprocess pour les mov)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #181020 - 00h57 env (durée : ...) ko (encore subprocess - pourtant corrigé -> ajout d'une exception)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #181020 - 1h36 env (durée : 4h env) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Picosmos\" #181020 - 13h30 env (qq secondes) ok (nouveaux types d'images : webp)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Svgd_iPhone\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos_classement\" #181020 - 17h env (45min) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos_svg_sur_MyBook_le181122\" #181020 - 19h10 env (2h) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\SvgWhatsapp\"\n",
    "#---DD FREEDOM---*\n",
    "#monRepertoire = r\"D:\\IPhone\" #dd freedom le 231020 19h45 env - 30 min\n",
    "#monRepertoire = r\"D:\\Photos\" #dd freedom le 231020 à 20h30 env - 1h30\n",
    "#monRepertoire = r\"D:\\Sauvegardes_HTC\" #dd freedom le 231020 à 22h32 env 32 min\n",
    "#monRepertoire = r\"D:\\SG-2010-2013\"  #dd freedom le 231020 - images_videos  : plantage (fichier sans extension) - correction  \n",
    "     #                                                     - documents_test : plantage : NON RESOLU - A VOIR...\n",
    "     #print('.............<fnph_getstats_file>..............')\n",
    "     #46 \n",
    "     #---> #47     s_obj=os.stat(os.path.join(parm_mondir, parm_monfichier))\n",
    "     #48     mydicoresult = {k:getattr(s_obj,k) for k in dir(s_obj) if k.startswith(\"st_\")}\n",
    "     #49     #print('\\n',parm_monfichier, ':', mydicoresult)\n",
    "     #OSError: [WinError 1006] Le fichier ouvert n’est plus valide car le volume qui le contient a été endommagé \n",
    "     #                         de manière externe: 'D:\\\\SG-2010-2013\\\\Bureau\\\\A_Classer\\\\screenshot 1.jpg'\n",
    "#monRepertoire = r\"D:\\Videos\" #dd freedom le 231010 à 22h42 env. 44 secondes\n",
    "#---DD WD---*\n",
    "#monRepertoire = r\"D:\\A_METTRE_SUR_CD_surDD150418\" ## DD WD - le 241020 à 14h03 env. 5h+ platange sur \n",
    "# \"D:\\A_METTRE_SUR_CD_surDD150418\\JL_130101_DCIM_HTC_okbis\\DCIM\\.Thumbs\\08.jpg.png\"\n",
    "monRepertoire = r\"D:\\A_METTRE_SUR_CD_surDD150418\" ## DD WD - refait le 241020 à 19h012 env. ... \n",
    "\n",
    "#----------------------------------------------------------------------------*\n",
    "\n",
    "#ajout de monRepertoire à montitre_traitement\n",
    "montitre_traitement += \"(\"+monRepertoire+\")\"\n",
    "#------  TYPES DE FICHIERS  ------------------*\n",
    "#listes des extensions et leur label\n",
    "#Remarque : les contrôles se font sans la casse\n",
    "mes_types_images = {\n",
    "                '.BMP'  : 'image',                '.TIFF' : 'image',\n",
    "                '.tif'  : 'image',                '.JPEG' : 'image',\n",
    "                '.jpg'  : 'image',                '.jfif' : 'image',\n",
    "                '.pjpeg': 'image',                '.pgp'  : 'image',\n",
    "                '.GIF'  : 'image',                '.PNG'  : 'image',\n",
    "                '.svg'  : 'image',                '.webp' : 'image'\n",
    "                        }\n",
    "#ajout du 3gp le 24/10/20 19h05\n",
    "\n",
    "mes_types_videos = {\n",
    "                '.mp4' : 'video',                '.mov' : 'video',                '.3gp' : 'video',\n",
    "                '.avi' : 'video',                '.flv' : 'video',\n",
    "                '.wmv' : 'video',                '.mpeg': 'video',\n",
    "                '.mkv' : 'video',                '.asf' : 'video',\n",
    "                '.rm'  : 'video',                '.vob' : 'video',\n",
    "                '.ts'  : 'video',                '.dat' : 'video'\n",
    "                        }\n",
    "\n",
    "#mes_types_images = {'.xxx'  : 'pour test aucune image'}\n",
    "#mes_types_videos = {'.mov'  : 'pour test videos mov'  }\n",
    "\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "\n",
    "\n",
    "#----------------\n",
    "#DEBUT TRAITEMENT\n",
    "#----------------\n",
    "\n",
    "#----------------\n",
    "#initialisations\n",
    "#----------------\n",
    "\n",
    "#Compteurs\n",
    "log_nb_rep                = 0 #nombre de répertoires traités    \n",
    "GLOBAL_NUM_FLDR           = 0 #numéro du répertoire traité\n",
    "GLOBAL_NBTOTFILES_TREATED = 0 #nombre total de fichiers traités\n",
    "#df historique des répertoires traités\n",
    "df_log = pd.DataFrame(columns=['unique_id',\n",
    "                               'time',\n",
    "                               'rep_explored',\n",
    "                               'nb_sous_rep', 'nb_of_files', \n",
    "                               'nb_of_files_cumul', \n",
    "                               'comment'])\n",
    "#globa_unique_id : Variable de valeur unique pour rsgner unique_id lors des différents appels\n",
    "strtimestamp = str(datetime.timestamp(datetime.now()))\n",
    "global_unique_id = strtimestamp\n",
    "print('\\n           global_unique_id:', global_unique_id,'\\n')\n",
    "\n",
    "\n",
    "#teste l'existence du répertoire de sauvegarde du log avant de démarrer\n",
    "if not os.path.exists(parm_df_log_rep):\n",
    "    print('ERREUR : le répertoire de sauvegarde n''existe pas')\n",
    "    print('ERREUR : ' + parm_df_log_rep)\n",
    "    print('ERREUR : veuillez vérifier et relancer')\n",
    "    sys.exit(\"haa! errors! vérifier le nom du répertoire du log en paramètre et relancer\")\n",
    "\n",
    "#------------\n",
    "# TRAITEMENT\n",
    "#------------\n",
    "start_time=datetime.now()\n",
    "print('start..................... : ', start_time, '\\n')\n",
    "\n",
    "print('accès à', monRepertoire, 'pour récupérer le nombre de sous-répertoires et de fichiers...')\n",
    "print('...')\n",
    "monRepertoire_totalnb_files, monRepertoire_totalnb_fldrs = fnph_getstats_dir(monRepertoire) \n",
    "print('... ok') #- accès à', monRepertoire, 'pour récupérer le nombre de sous-répertoires et de fichiers...\\n')\n",
    "\n",
    "print(\"\\n**** Collection            :\", mycollection_name, \"****\\n\")\n",
    "print(\"**** Répertoire            :\"  , monRepertoire, \"****\\n\")\n",
    "print(\"****  nb folders (total)   :\"  , monRepertoire_totalnb_fldrs+1, \"****\\n\")\n",
    "print(\"****  nb files (tous types):\"  , monRepertoire_totalnb_files  , \"****\\n\" )\n",
    "\n",
    "print('remarque : les deux nombres après chaque répertoire correspondent')\n",
    "print('           au nombre de fichiers à la racine du répertoire et celui cumulé avec ceux des sous-répertoires')\n",
    "print('           de type recherché et qui ont été insérés ou mis à jours dans la base\\n')\n",
    "\n",
    "\n",
    "#ajout de la ligne start dans df_log \n",
    "#rmq : nb_sous_rep et nb_of_files sont les documents à la racine du répertoire, pas le total\n",
    "df_log=df_log.append({'unique_id'   :global_unique_id,\n",
    "                      'time'        :str(datetime.now()),\n",
    "                      'rep_explored':\" <--- début de traitement - <\"+montitre_traitement+\">-->\",\n",
    "                      'comment'     :\"start \"}, ignore_index=True)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#mise sous format lower pour comparaison sans prise en compte de la casse \n",
    "#(les extensions de fichiers lues sont mises en minuscules)\n",
    "# avec fusion des deux listes\n",
    "A, B = mes_types_images, mes_types_videos\n",
    "mydico_types = {key.lower():value for d in (A, B) for key,value in d.items()}\n",
    "\n",
    "#Début - insertion - Ajout de l'insertion d'un log + stats (taille globale et nombre de fichiers)\n",
    "fnph_startandend_ajout_evnmtppl_mongodb(\"début\",      montitre_traitement, monRepertoire, mydico_types, \n",
    "                                        mycollection, 0                  ,0             ,           [], \n",
    "                                        log_nb_rep, \"nb folders : \"+str(monRepertoire_totalnb_fldrs) +\n",
    "                                                    \"nb files   : \"+str(monRepertoire_totalnb_files),\n",
    "                                        mydo_copy, mydo_copy_dest_dir_name\n",
    "                                        )\n",
    "\n",
    "#incrémentation du nombre de répertoires traités (+1) et écriture dans le df log du traitement du répertoire initial\n",
    "#remarque : en fait, cette ligne (répertoire initial) sera réécrite par la fonction fnph_traitementrep avec\n",
    "#           les nombres correspondants de sous-répertoires. Je la laisse car elle permet d'identifier rapidement\n",
    "#           dans le df les répertoires de base de chaque traitement.\n",
    "log_nb_rep+=1\n",
    "df_log=df_log.append({'unique_id'   : global_unique_id,\n",
    "                      'time'        : str(datetime.now()),\n",
    "                      'rep_explored': monRepertoire,\n",
    "                      'comment'     :\"Répertoire initial\"}, ignore_index=True)\n",
    "\n",
    "#Appel pour traitement récursif du répertoire initial et cumul des compteurs et du nombre de répertoires\n",
    "#-------------------------------------------------------------------------------\n",
    "result = fnph_traitementrep(monRepertoire, mydico_types, mydb, df_log.columns, \n",
    "                            mydo_copy, mydo_copy_dest_dir_name)\n",
    "#-------------------------------------------------------------------------------\n",
    "log_nb_rep+=result[2]\n",
    "df_log=df_log.append(result[3])\n",
    "\n",
    "#Calcul de la taille globale de la base et du nombre de fichiers présents dans la base\n",
    "var_tailletot, var_nbtot = fnph_clc_nb_st_size_tot(mycollection)\n",
    "\n",
    "#Fin - Ajout de l'insertion d'un log + stats (taille globale et nombre de fichiers)\n",
    "end_time=datetime.now()\n",
    "fnph_startandend_ajout_evnmtppl_mongodb(\"fin\",        montitre_traitement, monRepertoire, mydico_types, \n",
    "                                        mycollection, var_tailletot,       var_nbtot,     result,\n",
    "                                        log_nb_rep, str(end_time - start_time),\n",
    "                                        mydo_copy, mydo_copy_dest_dir_name\n",
    "                                        )\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "msg    = ['']*12\n",
    "end_time=datetime.now()\n",
    "msg[0] = '\\ndone----------------------------------------'\n",
    "msg[1] = 'nombre répertoires explorés       : ' + str(log_nb_rep)\n",
    "msg[2] = 'nombre de fichiers traités        : ' + str(result[0]+result[1])\n",
    "msg[3] = 'dont nb insertions                : ' + str(result[0])\n",
    "msg[4] = 'et   nb updates                   : ' + str(result[1])\n",
    "msg[5] = 'taille ttle des fichiers en base  : ' + str(var_tailletot)\n",
    "msg[6] = 'nombre ttl de  documents en base  : ' + str(var_nbtot)\n",
    "msg[7] = 'Durée du traitement               : ' + str(end_time - start_time)\n",
    "msg[8] = ''\n",
    "msg[9] = ''\n",
    "msg[10] = 'done----------------------------------------'\n",
    "for i in range(len(msg)):\n",
    "    if msg[i]!='':\n",
    "        print(msg[i])\n",
    "\n",
    "#svg du df pour enregistrement du répertoire traité dans un df historique.\n",
    "for i in range(len(msg)):\n",
    "    if msg[i]!=\"\":\n",
    "        df_log=df_log.append({'unique_id'   : global_unique_id,\n",
    "                              'time'        : str(end_time),\n",
    "                              'rep_explored': \" <--- \" + monRepertoire + \" --- fin de traitement --->\",\n",
    "                              'comment'     : msg[i]}, ignore_index=True)\n",
    "\n",
    "#Sauvegarde du df_log - nom complété de la collection et nom du répertoire exploré\n",
    "dnow = datetime.now()\n",
    "strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "mypathlog=r'C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_log'\n",
    "#df_log_filename='prjph_df_log_'+ str(strtimestamp) + '.csv'\n",
    "df_log_filename= 'prjph_df_log__' +                                   \\\n",
    "                    global_unique_id.replace('.','_') + \"__\" +        \\\n",
    "                    mycollection_name + \"__\" +                        \\\n",
    "                   (monRepertoire.split(\"\\\\\")[-1]).replace(' ','_') + \\\n",
    "                 '.csv' #référencement avec global_unique_id utilisé pour référencer les documents dans la base.\n",
    "df_log.to_csv(os.path.join(mypathlog,df_log_filename), sep='\\t')\n",
    "print('df_log savec into', mypathlog)\n",
    "\n",
    "print('\\nended..................... : ', end_time, '\\n')\n",
    "\n",
    "#Programme principal fin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anomalie sur un fichier 3gp :\n",
    "\n",
    "#11/134[8%]Rép:D:\\A_METTRE_SUR_CD_surDD150418\\AmettresurCDTemp\\Annulé (peut être supprimé)\\Videos\n",
    "#   <lus/inRep:498/649) [76.73%] ... Mdata: VIDEO0453.3gp --- (cumul:22809/94069)timeleft:7:17:40/4:29:18>7:14:00/4:23:10>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)  \n",
    "pd.set_option('display.max_rows', df_log.shape[0]+1)\n",
    "#df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 2020-10-24 21:11:39.694453\n"
     ]
    }
   ],
   "source": [
    "#connection au serveur mongodb 27017, base test\n",
    "testclient = pymongo.MongoClient('localhost',27017)\n",
    "testmydb = testclient[\"prjph_catalogue\"]\n",
    "testmycollection = testmydb[\"test_documents\"]\n",
    "\n",
    "#mycollection.insert_one(datatest[\"data\"])\n",
    "print(\"done\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970:01:0101:00\n"
     ]
    }
   ],
   "source": [
    "#testdate = abs( datatest[\"data\"][datatosee][\"st_ctime\"] )\n",
    "testdate = 0.0\n",
    "print(datetime.fromtimestamp(testdate).strftime('%Y:%m:%d%H:%M'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
