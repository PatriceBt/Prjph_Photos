{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du catalogue de photos\n",
    "\n",
    "## Recherche de photos dans l'arbordescence sous-jacente au répertoire indiqué par l'utilisateur.\n",
    "\n",
    "### Objectif : avoir un outil permettant de référencer les photos et d'obtenir des statistiques :\n",
    "\n",
    "- permettre une sauvegarde des photos dans un dd unique (les dossiers d'origine sont conservés) tout en permettant\n",
    "de sauvegarder et \n",
    "\n",
    "- référencer d'éventuelles nouvelles photos sans avoir à tout référencer à nouveau (celles déjà\n",
    "référencés seront topées 'déjà présentes'\n",
    "\n",
    "- obtenir des dossiers (albums) constitués de copies de photos par classement souhaité (doublons possibles).\n",
    "\n",
    "Stats :\n",
    "- nombre d'images par année, mois, jour\n",
    "- nombre de doublons\n",
    "- nombre de photos par sujet\n",
    "\n",
    "\n",
    "\n",
    "### A voir : \n",
    "\n",
    "la gestion du réseau (paramétrages sécurisés)\n",
    "\n",
    "la taille de l'image stockée si stockée. A réduire éventuellement.\n",
    "\n",
    "\n",
    "### Priorités :\n",
    "\n",
    "La fonction de copie\n",
    "La création d'albums en fonction des dates.\n",
    "La sauvegarde d'albums sur clés usb (par années, par personne, par lieu).\n",
    "\n",
    "\n",
    "\n",
    "### Prochains points : \n",
    "\n",
    "- Copie des fichiers catalogués dans le matériel de stockage qui aura été choisi.\n",
    "\n",
    "- Vérifier la récupération de la date de fichier : \n",
    "\n",
    "    - Récupérer en priorité la date 'Origine/Prise de vue' des données exif (?) puis st_mtimt, notamment pour les jpg (si modif sur iPhone, alors la valeur est différente de la date de dernière modification (st_mtime).\n",
    "\n",
    "\n",
    "- Ajout d'un appel pour récupérer le nombre total de répertoires dans l'arboresence du répertoire initial\n",
    "  afin de pouvoir avoir une estimation de la durée de traitement.\n",
    "  \n",
    "- Ajout du nombre de fichiers lus (qqsoit le type de fichier) (pour avoir une idée de l'écart)\n",
    "\n",
    "- Notification des traitements sur cahier au fur et à mesure.    \n",
    "\n",
    "- Calcul du nombre de fichier et du volume mémoire avec la requête ci-dessus\n",
    "\n",
    "- Mise sous forme dataFrame de la base et sauvegarde en csv (pour manips sur Excel)\n",
    "\n",
    "- Stats sous Excel\n",
    "\n",
    "- Fin\n",
    "\n",
    "Le volume global va servir à étudier les solutions de stockage des copies.\n",
    "\n",
    "\n",
    "#### Points traités :\n",
    "\n",
    "- Identification de la donnée 'taille mémoire' de l'image (pour calcul du volume global) ----------------OK\n",
    "\n",
    "- Calcul de la taille globale : Requête de calcul de la somme des tailles mémoire -----------------------OK\n",
    "\n",
    "- Lancement d'une requête mongodb sur la bd via python et récupération du résultat dans une variable ----OK\n",
    "\n",
    "- Définition de la liste des extensions 'image' et 'vidéo' ----------------------------------------------OK\n",
    "\n",
    "    - Ajout d'un document 'log' qui contient ------------------------------------------------------------OK\n",
    "    - un titre illustrant le traitement lancé -----------------------------------------------------------OK\n",
    "    - la date -------------------------------------------------------------------------------------------OK\n",
    "    - le répertoire racine paramétré --------------------------------------------------------------------OK\n",
    "    - la liste des répertoires explorés (faire un df au fur et à mesure du print) -----------------------OK\n",
    "    \n",
    "  (utilité : avoir l'historique des répertoires consultés pour éviter de les refaire en cas de doute)\n",
    "\n",
    "\n",
    "\n",
    "### A venir :\n",
    "\n",
    "Fonctions à venir : \n",
    "COPIE - GESTION DES DOUBLONS - RECHERCHE - CLASSEMENT - CREATION D'ALBUMS SELON CRITERES - RECONNAISSANCE\n",
    "\n",
    "ajout de la sauvegarde d'une vignette de l'image dans la bd\n",
    "ajout du référencement des vidéos (=> ajout des types vidéos)\n",
    "faire le point sur les types de fichiers image et vidéo\n",
    "\n",
    "penser à faire un test (copie des répertoires photo, avec écriture bloquée)\n",
    "\n",
    "obtenir la liste des répertoires de photos avant la copie (pour les mettre en écriture interdite)\n",
    "\n",
    "ajout de la fonction COPIE:\n",
    "    même fonctionnement mais avec en plus une copie dans un dossier spécifé\n",
    "    + mise à jour de la bd (ajout événement copie / création enreg avec deux événements - insert et copie)\n",
    "    \n",
    "ajout de la fonction de gestion des doublons\n",
    "    à préciser\n",
    "    \n",
    "définir le lieu de stockage de la bd (cf. volume important si images stockées)\n",
    "\n",
    "\n",
    "### Réalisé\n",
    "\n",
    "21/10 : Les statistiques quantités et volumes par année, mois, jour, catégories, types de fichier (notebook statistiques).\n",
    "\n",
    "15/10 : création réseau. Accès au répertoire partagé.\n",
    "\n",
    "test sur le répertoire partagé\n",
    "\n",
    "ajout du stockage de l'image\n",
    "\n",
    "annulation du stockage de l'image - pourra être effectué ultérieurement.\n",
    "\n",
    "la correction de la récup des données exif (cf. en cours)\n",
    "\n",
    "le traitement de la donnée exif 37500, bytes très longue. A priori, le pop ne fonctionne pas.\n",
    "\n",
    "Répertoire et types de fichiers entrés en paramètres\n",
    "\n",
    "appel à la fonction prjph_listdirectory : récupération dans un dictionnaire des noms des fichiers avec os.listdir contenus dans le répertoire passé en paramètre et de type passé en paramètre également.\n",
    "\n",
    "Avec pour chaque fichier :\n",
    "\n",
    "    - récupération et ajout dans le dictionnaire des métadonnées exif avec PIL getexif (via fnph_getexif)\n",
    "      (avec suppression des données 37500, 37510 et 59932 car trop longues et a priori non utiles\n",
    "      , et suppression des clés dictionnaires)\n",
    "\n",
    "    - récupération et ajout dans le dictionnaire des stats par os.stats avec conversion en dicitonnaire (via fnph_getstats)\n",
    "    \n",
    "Mise à jour de la base mongo avec les fichiers contenus dans la liste obtenue :\n",
    "    \n",
    "    - recherche de la présence du fichier dans la base (par appel à la fonction prjph_alreadyexists\n",
    "    \n",
    "    - si le fichier n'est pas déjà présent : écriture des éléments du dictionnaire de données liées au fichier en cours \n",
    "    \n",
    "    - sinon, mise à jour du document dans la base par ajout d'un champ événement (identifiant unique créé avec la date)\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "### Fonctions cibles :\n",
    "\n",
    "- Demande de répertoire de recherche à l'utilisateur\n",
    "\n",
    "- Recherche d'images dans le répertoire indiqué et l'arborescence sous-jacente\n",
    "    format sélectionné : img, jpeg\n",
    "    \n",
    "- Pour chaque image : \n",
    "\n",
    "    - Récupération des caractéristiques de l'image\n",
    "    \n",
    "        . nom du fichier image\n",
    "        . emplacement d'origine (chemin)\n",
    "        . matériel (nom du disque dur)\n",
    "        . date de prise de vue\n",
    "        . appareil\n",
    "        . date de création du fichier origine\n",
    "        \n",
    "    - Mise à jour de la base de données :\n",
    "    \n",
    "        . date de mise à jour\n",
    "        . caractéristiques de l'image\n",
    "\n",
    "    En cas de présence dans le catalogue du couple (source, fichier) (cas d'un catalogue déjà effectué)\n",
    "    \n",
    "        . mise à jour de l'instance par ajout de l'événement (référencement ko) \n",
    "\n",
    "\n",
    "- Gestion d'un journal\n",
    "\n",
    "    Début de traitement :\n",
    "    \n",
    "        . Ecriture ligne :\n",
    "        \n",
    "            - références du traitement\n",
    "            - répertoire indiqué par l'utilisateur\n",
    "            - répertoire de copie (lieu de stockage de la base de données)\n",
    "            \n",
    "    Pour chaque copie\n",
    "    \n",
    "        . Ecriture ligne : \n",
    "        \n",
    "            - chemin du répertoire origine\n",
    "            - nom du fichier origine\n",
    "            - nom fichier sauvegardé (après gestion de doublon)\n",
    "            \n",
    "\n",
    "Remarques\n",
    "sur les extensions image\n",
    "https://developer.mozilla.org/fr/docs/Web/Media/Formats/Types_des_images\n",
    "    \n",
    "sur les extensions video\n",
    "https://www.reneelab.fr/extension-video.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "from PIL import Image, IptcImagePlugin\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt #je ne sais plus pourquoi\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt #pour timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "#pour les images\n",
    "import PIL.Image\n",
    "import gridfs\n",
    "#pour les images webp\n",
    "#!pip3 install webptools  #webp... et pas web...\n",
    "from webptools import dwebp\n",
    "#pip install opencv-python (pour cv2)\n",
    "#pour les vidéos\n",
    "import cv2\n",
    "import subprocess\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le code de récupération des fichiers images et référencement dans la base mongodb prjph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des fonctions de lecture du catalogue et d'insertion dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getexif(parm_monfichier):\n",
    "    \"\"\"\n",
    "        Fonction de recherche des métadonnées exif des images  -  see https://www.exiv2.org/tags.html pour les définitions\n",
    "        avec en plus un thumbnail\n",
    "        Retourne un dictionnaire\n",
    "        Problème de getexif sur une image de type gif\n",
    "        => solution mep : exception et sortie dictionnaire indiquant pbl\n",
    "                          retrait des types \".gif\" de la liste des types (extensions)\n",
    "        Problème PIL.Image.open sur un fichier m6c8282f3.jpg (dans un répertoire ...HTC_121212.bookmark_thumb1)\n",
    "        => solution mep : exception et sortie dico avec pbl\n",
    "    \"\"\"\n",
    "    bool_img_ok=True\n",
    "    bool_dict_exif_ok=True\n",
    "    try:\n",
    "        img = PIL.Image.open(parm_monfichier)\n",
    "    except:\n",
    "        bool_img_ok=False\n",
    "        bool_dict_exif_ok=False\n",
    "        msg_err = \"Problème ouverture PIL.Image.open\"\n",
    "        \n",
    "    #print('debug-->parm_monfichier=', parm_monfichier)\n",
    "    #print('debug-->type(img)=',type(img))\n",
    "    \n",
    "    #données exif\n",
    "    if bool_img_ok:\n",
    "        try:\n",
    "            dict_exif = img._getexif()\n",
    "        except:\n",
    "            bool_dict_exif_ok=False\n",
    "            msg_err = \"Données exif non récupérées - problème de format de fichier (gif par exemple) ?\"\n",
    "        \n",
    "    #debug\n",
    "    #print('debug-->', [(k,type(v),len(str(v))) for k,v in dict_exif.items()])\n",
    "   \n",
    "    if bool_dict_exif_ok:\n",
    "        #initialisation de la liste des données à supprimer (pas directement sinon pbl de taille de dico qui varie...)\n",
    "        listpop=[]\n",
    "        try:\n",
    "            debug_cpt=0\n",
    "            for k,v in dict_exif.items():\n",
    "                debug_cpt+=1\n",
    "                #print('debug-->gestion des données exif - ', debug_cpt)\n",
    "                #print('debug-->test format de v pour k,v =', k, type(v))\n",
    "                #conversion du type PIL.TiffImagePlugin.IFDRational en string avec ajout du liellé IFDRational\n",
    "                if type(v)==PIL.TiffImagePlugin.IFDRational:\n",
    "                    dict_exif[k]='IFDRational '+str(v)\n",
    "                    #print('debug-->ifdrational', k, v)\n",
    "                #et gestion de 42034 (valeur de type tuple avec données Tiff, transformée en string)\n",
    "                if k == 42034: #éventuellement à remplacer par un test sur type tuple s'il y en a d'autres\n",
    "                    dict_exif[k]=str(v)\n",
    "                #je retire les données bytes de plus de 12 de long\n",
    "                if type(v) == bytes and len(str(v)) > 12:\n",
    "                    #print('debug-->bytes trop longs :', k, 'supprimée')\n",
    "                    listpop.append(k)\n",
    "\n",
    "            #Suppression des données \n",
    "            for i in range(len(listpop)):\n",
    "                dict_exif.pop(listpop[i])\n",
    "\n",
    "        except:\n",
    "            #print('debug-->except on k, v=',k, v)\n",
    "            mytrue=True\n",
    "\n",
    "        #suppression des clés de type dictionnaire\n",
    "        listpop=[]  #initialisation de la liste des données à supprimer (pas directement sinon pbl de taille de dico qui varie...)\n",
    "        try:\n",
    "            for k,v in dict_exif.items():\n",
    "                if type(v)==dict:\n",
    "                    listpop.append(k)\n",
    "            for i in range(len(listpop)):\n",
    "                dict_exif.pop(listpop[i])\n",
    "        except:\n",
    "            mytrue=True\n",
    "\n",
    "        #conversion des clés (elles sont toutes en numériques) en string (si le dictionnaire est renseigné)\n",
    "        if dict_exif != None:\n",
    "            dict_exif = {str(key):value for (key,value) in dict_exif.items()}\n",
    "    \n",
    "    else:\n",
    "        #Cas où dict_exif._getexif ne fonctionne pas (fichiers .gif par exemple) -> restitution d'un dico 'vide'\n",
    "        dict_exif = {\"msg_err\":msg_err}\n",
    "        \n",
    "    #ajout du thumbnail dans le dictionnaire exif\n",
    "    #...\n",
    "    # A VOIR\n",
    "    #...\n",
    "    #size=(100,100)\n",
    "    #imgth=img.copy()\n",
    "    #print(imgth)\n",
    "    #dict_exif['thumbnail']=imgth.thumbnail(size)\n",
    "    #dict_exif['image']=img\n",
    "\n",
    "    return dict_exif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test de la fonction fnph_getexif\n",
    "\n",
    "testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\uneimage\"\n",
    "\n",
    "f='JL_091103 019.jpg'\n",
    "#f='test.jpg'\n",
    "#f='Captureph1.jpg'\n",
    "#f='Capturefondbl.JPG'\n",
    "test=fnph_getexif(join(testRepertoire,f))\n",
    "len(test)\n",
    "\n",
    "#for k,v in test.items():\n",
    "#    print('test-->', k,v,type(v),len(str(v)))\n",
    "#    if type(v)==PIL.TiffImagePlugin.IFDRational:\n",
    "#        print('class pil -> conversion en string', str(v))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getiptc(parm_dir, parm_file):\n",
    "    # pip install pillow\n",
    "    #parm_dir=r'C:\\Users\\LENOVO\\Pictures'\n",
    "    #parm_file='Capturenb.JPG'\n",
    "    \"\"\"\n",
    "    Recherche les informations iptc d'une image \n",
    "    Retourne une liste : 1er élément vrai/faux 2ème:iptc (format dico pour mongo) si ok\n",
    "    \"\"\"\n",
    "\n",
    "    #from PIL import Image, IptcImagePlugin\n",
    "\n",
    "\n",
    "    im = Image.open(os.path.join(parm_dir, parm_file))\n",
    "    \n",
    "    iptc = IptcImagePlugin.getiptcinfo(im)\n",
    "\n",
    "    if iptc:\n",
    "        for k, v in iptc.items():\n",
    "            print(\"{} {}\".format(k, repr(v.decode())))\n",
    "        print('debug--> IPTC INFO TROUVEES !!!!!!!!!!!!!!!!!!!!!!', parm_file)\n",
    "        result=[{\"getiptc\":True ,\"iptc\":iptc}]\n",
    "    else:\n",
    "        #print(\"debug--> This image has no iptc info\")\n",
    "        result=[{\"getiptc\":False , \"iptc\":\"no iptc info\"}]\n",
    "        \n",
    "    return(result)\n",
    "    # We can user getter function to get values\n",
    "    # from specific IIM codes\n",
    "    # https://iptc.org/std/photometadata/specification/IPTC-PhotoMetadata\n",
    "    #def get_caption():\n",
    "    #    return iptc.get((2,120)).decode()\n",
    "    #\n",
    "    #print(get_caption())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test fnph_getiptc\n",
    "\n",
    "\n",
    "parm_dir=r'C:\\Users\\LENOVO\\Pictures'\n",
    "parm_file='Capturenb.JPG'\n",
    "fnph_getiptc(parm_dir, parm_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getstats_file(parm_mondir, parm_monfichier):\n",
    "    \"\"\"fonction de recherche des données stats de l'image par os.stats\n",
    "       avec restitution des données st_ sous forme de dictionnaire\n",
    "       pour os.stat see https://docs.python.org/2/library/os.html \n",
    "       os.stat(path) perform the equivalent of a stat() system call on the given path. \n",
    "       \n",
    "    The return value is an object whose attributes correspond to the members of the stat structure, namely:\n",
    "        st_mode - protection bits,\n",
    "        st_ino - inode number,\n",
    "        st_dev - device,\n",
    "        st_nlink - number of hard links,\n",
    "        st_uid - user id of owner,\n",
    "        st_gid - group id of owner,\n",
    "        st_size - size of file, in bytes,\n",
    "        st_atime - time of most recent access,\n",
    "        st_mtime - time of most recent content modification,\n",
    "        st_ctime - platform dependent; time of most recent metadata change on Unix, or the time of creation on Windows)\n",
    "\n",
    "    Changed in version 2.3: If stat_float_times() returns True, the time values are floats, measuring seconds. \n",
    "    Fractions of a second may be reported if the system supports that. See stat_float_times() for further discussion.\n",
    "\n",
    "    On some Unix systems (such as Linux), the following attributes may also be available:\n",
    "    st_blocks - number of 512-byte blocks allocated for file\n",
    "    st_blksize - filesystem blocksize for efficient file system I/O\n",
    "    st_rdev - type of device if an inode device\n",
    "    st_flags - user defined flags for file\n",
    "\n",
    "    On other Unix systems (such as FreeBSD), the following attributes may be available (but may be only filled out if root tries to use them):\n",
    "    st_gen - file generation number\n",
    "    st_birthtime - time of file creation\n",
    "\n",
    "    On RISCOS systems, the following attributes are also available:\n",
    "    st_ftype (file type)\n",
    "    st_attrs (attributes)\n",
    "    st_obtype (object type).\n",
    "\n",
    "    Note The exact meaning and resolution of the st_atime, st_mtime, and st_ctime attributes depend on the operating system \n",
    "    and the file system. For example, on Windows systems using the FAT or FAT32 file systems, st_mtime has 2-second resolution,\n",
    "    and st_atime has only 1-day resolution. \n",
    "    See your operating system documentation for details.\n",
    "\n",
    "    For backward compatibility, the return value of stat() is also accessible as a tuple of at least 10 integers giving the most important (and portable) members of the stat structure, in the order st_mode, st_ino, st_dev, st_nlink, st_uid, st_gid, st_size, st_atime, st_mtime, st_ctime. More items may be added at the end by some implementations.\n",
    "    The standard module stat defines functions and constants that are useful for extracting information from a stat structure. (On Windows, some items are filled with dummy values.)\n",
    "    \"\"\"\n",
    "    #print('.............<fnph_getstats_file>..............')\n",
    "\n",
    "    s_obj=os.stat(os.path.join(parm_mondir, parm_monfichier))\n",
    "    mydicoresult = {k:getattr(s_obj,k) for k in dir(s_obj) if k.startswith(\"st_\")}\n",
    "    #print('\\n',parm_monfichier, ':', mydicoresult)\n",
    "    return mydicoresult\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_listDirectory(parm_directory, parm_fileExtDico, parm_db):                                        \n",
    "    \"\"\" get list of file info objects for files of particular extensions (sans sensibilité à la casse)\n",
    "        \n",
    "        Cette fonction recherche la liste des fichiers du répertoire parm_directory\n",
    "        puis recherche les metadonnées des fichiers du répertoire parm_directory\n",
    "        \n",
    "        parm_db est utilisé pour préparer le stockage de l'image par la fonction fnph_getimage\n",
    "        \n",
    "        parm_fileExtDico est la liste des extensions sous forme de dictionnaire {extension, libellé type de fichier}\n",
    "        Cela permet d'indiquer le type de fichier en clair dans doctype\n",
    "        Le dico est traduit en liste ensuite ici\n",
    "        C'est la liste qui est transmise aux fonctions appelées ici (elles n'ont pas besoin du label)\n",
    "\n",
    "        Elle retourne une liste de dictionnaire des données à insérer - un item par fichier\n",
    "    \"\"\"\n",
    "    \n",
    "    #Traitement du dico des types\n",
    "    #Création de la liste des types\n",
    "    fileExtList = [ ext for ext,label in parm_fileExtDico.items()]\n",
    "    #print('debug-->parm_fileExtDico=',parm_fileExtDico)\n",
    "    #print('debug-->fileExtList='     ,fileExtList)\n",
    "    #print('debug-->fonction..<fnph_listDirectory>..............', str(datetime.now()))\n",
    "    #pour la date \n",
    "    dnow = datetime.now()\n",
    "    strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "    #fieldname = 'event_'+str(strtimestamp)\n",
    "    fieldname = 'event_'+global_unique_id.replace('.','_') #on met un identifiant unique pour tous les fichiers du même traitement\n",
    "   \n",
    "    #initialisations avant la boucle sur les fichiers du répertoire\n",
    "    nb_files=0\n",
    "    listdata=[]\n",
    "    display1_ok=False\n",
    "    #print('debug-->début boucle sur les fichiers de os.listdir(parm_directory)', str(datetime.now()))\n",
    "    #-------\n",
    "    #print('Rép:', parm_directory)\n",
    "    fnph_incremente_GLOBAL_NUM_FLDR()\n",
    "    prct=GLOBAL_NUM_FLDR/(monRepertoire_totalnb_fldrs+1) #+1 pour compter le répertoire racine également traité\n",
    "    percentage = \"{:.0%}\".format(prct) \n",
    "    #print('{}/{}-Rép: {}[{}]'.format(GLOBAL_NUM_FLDR,monRepertoire_totalnb_fldrs+1,parm_directory,percentage))\n",
    "    print('{}/{}[{}]Rép:{}'.format(GLOBAL_NUM_FLDR,monRepertoire_totalnb_fldrs+1,percentage,parm_directory))\n",
    "    #-------\n",
    "    \n",
    "    #lenlistfile=len(os.listdir(parm_directory)) #pour print uniquement\n",
    "    #création de la liste des fichiers du répertoire (pour extraction des métadonnées et svg dans bd)\n",
    "    mylistfile = [myfile for myfile in os.scandir(parm_directory) if myfile.is_file()]\n",
    "    lenlistfile=len(mylistfile)                  #pour print uniquement\n",
    "    cpt=0                                        #pour print uniquement\n",
    "    #Boucle sur les fichiers du répertoire parm_directory\n",
    "    #for f in os.listdir(parm_directory):\n",
    "    #...remplacé par...\n",
    "\n",
    "    #------------------------------------------------------------------\n",
    "    #Boucle sur les fichiers de la liste pour recherche des metadonnées\n",
    "    #       et préparation de l'enregistrement à insérer dans la base (données + description événement)\n",
    "    #------------------------------------------------------------------\n",
    "    for f in mylistfile: #ATTENTION : LES ELEMENTS DE mylistfile SONT DES NT.ENTRIES (pas des strings)\n",
    "        cpt+=1\n",
    "        #print('debug-->dans la boucle, pour f=', f, str(datetime.now()))\n",
    "        fileDict={}\n",
    "        f_name=f.name\n",
    "        f_ext =\".\"+f_name.split('.')[1].lower()\n",
    "        #if (str(os.path.splitext(f)[1])).lower() in fileExtList:    #ajout de .lower() pour être insensible à la casse\n",
    "        if f_ext in fileExtList:    #ajout de .lower() pour être insensible à la casse\n",
    "           #pour affichage sysout ------------\n",
    "            #--pourcentage\n",
    "            prct=cpt/lenlistfile\n",
    "            percentage = \"{:.2%}\".format(prct)\n",
    "            #--la durée restante :\n",
    "            nb_totalfiles_treated = fnph_incremente_GLOBAL_NBTOTFILES_TREATED()\n",
    "            duree_restante        = fnph_duree_restante(start_time, \n",
    "                                                        datetime.now(), \n",
    "                                                        nb_totalfiles_treated, \n",
    "                                                        monRepertoire_totalnb_files) #nombre surestimé puisque tous types confondus\n",
    "\n",
    "            #pour chaque fichier,\n",
    " \n",
    "            #----\n",
    "            #--Affichage sur la même ligne\n",
    "            msgtodisplay1=\"   <lus/inRep:\"+ str(cpt) + \"/\" + str(lenlistfile) + \") \" + \\\n",
    "                          \"[\" + percentage + \"] \" + \\\n",
    "                          \"... Mdata: \" + f_name + \" ---\" + \\\n",
    "                          \" (cumul:\"+ str(nb_totalfiles_treated) +\"/\"+ str(monRepertoire_totalnb_files) + \")\"+ \\\n",
    "                          \"timeleft:\" + str(duree_restante).split('.')[0] + \">\"\n",
    "            sys.stdout.write(\"\\r\" + msgtodisplay1)\n",
    "            sys.stdout.flush()\n",
    "            display1_ok=True #pour gestion de l'affichage\n",
    "            #print(msgtodisplay1)\n",
    "            \n",
    "            #pour affichage sysout ------------\n",
    "            #----\n",
    "            #si son extension fait partie de celles retenues dans parm_fileExtDico (via fileExiList) - go dico\n",
    "    \n",
    "            #catégorie de fichier (image, vidéo)\n",
    "            #var_catfile=parm_fileExtDico[os.path.splitext(f)[1].lower()]\n",
    "            var_catfile=parm_fileExtDico[f_ext.lower()]\n",
    "            fileDict['doctype']=var_catfile  #récupération dans le dico du label du type\n",
    "            #chemin d'origine\n",
    "            fileDict['orgnl_dirname']=parm_directory, \n",
    "            #nom du fichier complet original\n",
    "            #fileDict['filename']=f\n",
    "            fileDict['filename']=f.name            #suite à l'utilisation de scandir\n",
    "            #extension du fichier (en lower case)\n",
    "            #fileDict['extfile']=os.path.splitext(f)[1].lower()\n",
    "            fileDict['extfile']=f_ext\n",
    "            #stats du fichier\n",
    "            fileDict['stats']=fnph_getstats_file(parm_directory,f)  #récupération de stats : \n",
    "                                                         #mode, ino, dev, nling, uid, gid, size, atime, mtime, ctime) \n",
    "            #Metadonnées (images et vidéos)\n",
    "            if var_catfile=='image':  #à voir comment généraliser (pour éviter la valorisation en dur)\n",
    "            #si image\n",
    "                #exif (si image) \n",
    "                #fileDict['exif'] =fnph_getexif(os.path.join(parm_directory,f))      #récupération des métadonnées exif\n",
    "                fileDict['exif'] =fnph_getexif(os.path.join(parm_directory,f.name))  #récupération des métadonnées exif\n",
    "                #l'image elle même (réduite?) si image (rendu inactif pour l'instant - ralentit pas mal)\n",
    "               #fileDict['image']=fnph_getimage(parm_directory,f, parm_db)      #récup des métadonnées pour stockage de l'image (nécessite la bd)\n",
    "            if var_catfile=='video':  #à voir comment généraliser (pour éviter la valorisation en dur)\n",
    "            #si vidéo\n",
    "                fileDict['vid_ppty']=fnph_get_video_properties(os.path.join(parm_directory,f))\n",
    "            \n",
    "            #pour tous les types d'images : recherche des données iptc - annulé pour l'instant (ne fonctionne pas)\n",
    "           #fileDict['iptc']=fnph_getiptc(parm_directory,f)      #récup des données iptc (si existent) (inactif pour l'instant - ralentit)\n",
    "            \n",
    "            #events\n",
    "            fileDict['events']={fieldname:{'edate':str(dnow),\n",
    "                                           'ename':'insert' ,\n",
    "                                           'estatus':'ok'   }}\n",
    "        \n",
    "            #Append dans la liste\n",
    "            listdata.append(fileDict)\n",
    "            nb_files+=1\n",
    "            #print('debug-->fin boucle sur f=', f, str(datetime.now()))\n",
    "\n",
    "    #print('debug-->sortie boucle sur les fichiers de os.listdir(parm_directory)', str(datetime.now()))\n",
    "    #Affichage du nombre de fichiers trouvés\n",
    "    #print(\"debug-->recherche des fichier de type \", fileExtList, \"dans le répertoire\", parm_directory)\n",
    "    #print('debug-->nombre de fichiers trouvés de type spécifié: ', nb_files,'.')\n",
    "    if display1_ok: #pour passer à la ligne après le dernier sys.std (display1) s'il y en a eu\n",
    "        msglibre=\"\" #se place en fin de ligne\n",
    "        print(msglibre)\n",
    "        \n",
    "    return listdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test de la fonction fnph_listDirectory (nécessite fnph...)\n",
    "\n",
    "strtimestamp = str(datetime.timestamp(datetime.now()))\n",
    "global_unique_id = strtimestamp\n",
    "\n",
    "#connection au serveur mongodb 27017, base test\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "mycollection = mydb[\"test_documents\"]\n",
    "\n",
    "#ou encore mycollection = client.prjph_catalogue.test_documents\n",
    "test_dir=r'C:\\Users\\LENOVO\\Pictures'\n",
    "#il faut maintenant un dictionnaire\n",
    "test_type={'.jpg':'image','.png':'image'}\n",
    "\n",
    "test=fnph_listDirectory(test_dir, test_type, mydb)                                        \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de recherche de présence de document dans la base\n",
    "def fnph_alreadyexists(parm_dirname, parm_filename):\n",
    "    \"\"\"\n",
    "    retourne un booléen\n",
    "    \"\"\"\n",
    "\n",
    "   #print('.............<fnph_alreadyexists>..............', parm_filename)\n",
    "   #print('debug-->recherche de parm_dirname =',parm_dirname)\n",
    "   #print('debug-->       et de parm_filename=',parm_filename)\n",
    "    f=parm_filename\n",
    "    if mycollection.count_documents({\"orgnl_dirname\":parm_dirname,\"filename\":parm_filename}, limit=1):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "   #print('debug-->result = ',result)\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'incrémentation de la variable globale global_num_fldr\n",
    "def fnph_incremente_GLOBAL_NUM_FLDR():\n",
    "    \"\"\"\n",
    "    incrémente la variable global_num_fldr qui donne le numéro d'ordre du répertoire traité\n",
    "    \"\"\"\n",
    "    global GLOBAL_NUM_FLDR\n",
    "    GLOBAL_NUM_FLDR = GLOBAL_NUM_FLDR + 1\n",
    "    return(GLOBAL_NUM_FLDR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction d'incrémentation de la variable globale global_nbtotfiles_treated\n",
    "def fnph_incremente_GLOBAL_NBTOTFILES_TREATED():\n",
    "    \"\"\"\n",
    "    incrémente la variable global_num_fldr qui donne le numéro d'ordre du répertoire traité\n",
    "    \"\"\"\n",
    "    global GLOBAL_NBTOTFILES_TREATED\n",
    "    GLOBAL_NBTOTFILES_TREATED = GLOBAL_NBTOTFILES_TREATED + 1\n",
    "    return(GLOBAL_NBTOTFILES_TREATED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_duree_restante(parm_timestart, parm_timenow, parm_nb_treated, parm_nb_tot):\n",
    "    \"\"\"\n",
    "    calcul de la durée restante estimée après traitement de parm_nb_treated éléments sur une durée\n",
    "    donnée par parm_timenow - parm_timestart\n",
    "    \"\"\"\n",
    "    timepast           = parm_timenow - parm_timestart\n",
    "    timepast_per_file  = timepast/parm_nb_treated\n",
    "    nb_files_remaining = parm_nb_tot - parm_nb_treated\n",
    "    duree_restante = nb_files_remaining * (timepast_per_file + dt.timedelta(seconds=0.055)) #ajout de 0.055s par file\n",
    "                                                                                             # pour la partie insert/update\n",
    "\n",
    "    return(duree_restante) #à afficher avec str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST fnph_duree_restante\n",
    "GLOBAL_NBTOTFILES_TREATED = 0\n",
    "test_monRepertoire_totalnb_files = 2 #monRepertoire_totalnb_files\n",
    "\n",
    "test_dnow       = datetime.now()\n",
    "test_start_time = test_dnow.replace(minute=test_dnow.minute-1) # moins 1 minute\n",
    "\n",
    "test_nbtotfiles_treated = fnph_incremente_GLOBAL_NBTOTFILES_TREATED()\n",
    "duree_restante = fnph_duree_restante(test_start_time, \n",
    "                                     test_dnow,\n",
    "                                     test_nbtotfiles_treated, \n",
    "                                     test_monRepertoire_totalnb_files) #nombre surestimé puisque tous types confondus\n",
    "\n",
    "str(test_start_time), str(test_dnow), test_monRepertoire_totalnb_files, str(duree_restante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_cat_filesofonedirectory(parm_monRepertoire, parm_dicotypes, parm_mydb):\n",
    "    \"\"\"\n",
    "    fonction de recherche des fichiers de type ceux passés en paramètres parm_types dans le répertoire passé en paramètres\n",
    "    avec récupération des metadonnées (exif, ...)\n",
    "    et insertion du fichier et des metadonnées dans la bd si non déjà présent\n",
    "    et retourne le nombre d'insertions effectuées, et le nombre de mise à jour\n",
    "    (ajout de parm_mydb pour l'appel à fnph_listDirectory pour l'appel à fnph_getimage)\n",
    "    \n",
    "    remarque : parm_types est un dictionnaire et uniquement passé aux fonctions appelées\n",
    "    \"\"\"\n",
    "    \n",
    "    #print('debug-->........<fnph_cat_filesofonedirectory>..............'+str(datetime.now()))\n",
    "\n",
    "    nb_insert=0\n",
    "    nb_update=0\n",
    "    display2_ok=False #pour gestion de l'affichage\n",
    "    #on peut ajouter ici les stats par catégorie image/vidéo avec mylist[i]['cat_img']\n",
    "    \n",
    "    #1-------------------------------------\n",
    "    #Recherche des données à enregistrer dans la base pour chaque fichier dans parm_monRepertoire -> mylist\n",
    "    #print('debug-->début appel fnph_listDirectory', str(datetime.now()))\n",
    "    mylist = fnph_listDirectory(parm_monRepertoire, parm_dicotypes, parm_mydb)\n",
    "    #print(\"\\nretour de fnph_listDirectory\")\n",
    "    #print('debug-->fin   appel fnph_listDirectory', str(datetime.now()))\n",
    "    #print('debug--> len(mylist)=', len(mylist))\n",
    "    \n",
    "    #2-------------------------------------\n",
    "    #Ecriture de la liste des éléments dans la bd, élément par élément avec test de présence\n",
    "    #print('debug-->Ecriture ou màj des élément trouvés')\n",
    "    #for i in tqdm.tqdm(range(len(mylist))):    #avec affichage de la barre de progression\n",
    "    nb_files_in_rep=len(mylist) #pour l'affichage et éviter les calculs redondants (va plus vite ?)\n",
    "    for i in range(nb_files_in_rep):\n",
    "        test_dirname  = mylist[i][\"orgnl_dirname\"]\n",
    "        test_filename = mylist[i][\"filename\"]\n",
    "        #print('debug-->', i, test_dirname[:20]+'...'+test_dirname[-40:], test_filename)\n",
    "        #pour l'affichage------------------------------------------------------------------------\n",
    "        #on écrit ici en sysout sur la même ligne pour donner une vision de l'avancement\n",
    "        prct=(i+1)/nb_files_in_rep\n",
    "        percentage = \"{:.2%}\".format(prct)\n",
    "\n",
    "        msgtodisplay2=\"\\r\" + \"   <indb/toPut:\" + str(i+1) + \"/\" + str(len(mylist)) + \")\" + \\\n",
    "                         \"[\" + percentage + \"] ... InsUp: \" + \\\n",
    "                          test_filename + \" \" + \\\n",
    "                         \"---\" + \">\"\n",
    "        sys.stdout.write(\"\\r\" + msgtodisplay2)\n",
    "        sys.stdout.flush()\n",
    "        display2_ok=True #pour gestion de l'affichage\n",
    "        #print(msgtodisplay2)\n",
    "        \n",
    "        #----------------------------------------------------------------------------------------\n",
    "\n",
    "        #test de présence dans la base\n",
    "        if fnph_alreadyexists(test_dirname, test_filename):\n",
    "            #UPDATE\n",
    "            #print('<fnph_cat_f...> existe déjà  -> màj       de mylist[',i,'] --------', str(mylist[i])[0:40], '.........')\n",
    "            ##### mise à jour par ajout de champ dans un champ existant (utilisation de .)\n",
    "            dnow = datetime.now()\n",
    "            #strnow = str(dnow.year)[:2]+str(dnow.month)+str(dnow.day)+str(dnow.hour)+str(dnow.minute)+str(dnow.second)+'_'+str(dnow.microsecond)\n",
    "            strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "           #fieldname = 'events.event_'+str(strtimestamp)\n",
    "            fieldname = 'events.event_'+global_unique_id.replace('.','_') #on met un identifiant unique pour tous les fichiers du même traitement\n",
    "               \n",
    "            result = mycollection.update_many( \n",
    "                         {\"orgnl_dirname\":test_dirname,\"filename\":test_filename}, \n",
    "                         {'$set':{fieldname:{'edate':str(dnow),\n",
    "                                             'ename':'insert ko',\n",
    "                                             'estatus':'already exists',\n",
    "                                             }}} )\n",
    "            nb_update+=1\n",
    "            \n",
    "        else:\n",
    "            #INSERT\n",
    "            #print('<fnph_cat_f...> n''existe pas -> insertion de mylist[',i,'] --------', str(mylist[i])[0:40], '.........')\n",
    "            mycollection.insert_one(mylist[i])\n",
    "            nb_insert+=1\n",
    "            \n",
    "    \n",
    "    if display2_ok:\n",
    "        msglibre=\"\"\n",
    "        print(msglibre) #ce print pour passer à la ligne - s'ajoute en fin de ligne\n",
    "    return [nb_insert,nb_update]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction récursive de traitement d'un répertoire\n",
    "\n",
    "def fnph_traitementrep(parm_rep, parm_dicotypes, parm_mydb, parm_df_log_cols):\n",
    "    \"\"\"fonction récursive de traitement d'un répertoire et de ses sous-répertoires\n",
    "        par lecture des sous-répertoires\n",
    "        et pour chacun, appel récursif de la fonction pour effectuer le même traitement\n",
    "        puis traitement des fichiers du répertoire courant\n",
    "        parm_df_log_cols sert à récupérer la structure du df historique (pour simplifier les éventuelles modif de structure)\n",
    "        retourne \n",
    "        - le nombre d'insert et d'update\n",
    "        - le nombre d'update\n",
    "        - le nombre de répertoires explorés\n",
    "        - le df_log (!)\n",
    "        (ajout de parm_mydb pour appel à fnph_getimage appelée dans les fonctions appelées)\n",
    "        \n",
    "        remarque : parm_dicotypes est un dictionnaire, et il est juste transmis aux fonctions appelées\n",
    "    \"\"\"\n",
    "    #from os import listdir\n",
    "    #from os.path import isfile, join, isdir\n",
    "\n",
    "    #print('.............<fnph_traitementrep>..............')\n",
    "    #print('Répertoire exploré :', parm_rep)\n",
    "    \n",
    "    #Initialisation des compteurs d'insertion et mise à jour\n",
    "    nbtot_insert = 0\n",
    "    nbtot_update = 0\n",
    "    #Initialisation des compteurs de répertoires explorés et du dataframe historique\n",
    "    local_log_nb_rep = 0\n",
    "    local_df_log     = pd.DataFrame(columns=parm_df_log_cols) \n",
    "\n",
    "    #----------------------------------------------\n",
    "    #1)recherche des répertoires (sous-répertoires)\n",
    "    #----------------------------------------------\n",
    "    #print(\"debug-->début liste_repertoires\", str(datetime.now()))\n",
    "    liste_repertoires = [r for r in listdir(parm_rep) if isdir(join(parm_rep, r))]\n",
    "    #possible ici de remplacer par scandir... à voir\n",
    "    \n",
    "    #print(len(liste_repertoires), 'sous-répertoires trouvés:',liste_repertoires)\n",
    "    #print(\"debug-->fin   liste_repertoires\", str(datetime.now()))\n",
    "    \n",
    "    #Traitement des répertoires (appel récursif) pour traitement des fichiers et des (sous-)répertoires\n",
    "    #print('debug-->Traitement des sous-répertoires-----liste_repertoires=', liste_repertoires)\n",
    "    #for onerep in tqdm.tqdm(liste_repertoires):   #avec affichage de la barre de progression\n",
    "    #print(\"debug-->début boucle onerep \"+str(datetime.now()))\n",
    "    for onerep in liste_repertoires:\n",
    "        #print('debug-->onerep=', onerep, datetime.now())\n",
    "        #pour chaque sous-rep trouvé :\n",
    "        local_log_nb_rep+=1 #incrémentation du nombre de répertoires traités à chaque répertoire traité\n",
    "        \n",
    "        #déplacé plus bas\n",
    "        #ajout (append) du répertoire traité 'parm_rep' dans le df historique\n",
    "        #local_df_log     = local_df_log.append({'time'        : str(datetime.now()),\n",
    "        #                                        'rep_explored': os.path.join(parm_rep,onerep),\n",
    "        #                                        'comment'     : \"sous-répertoire\"}, \n",
    "        #                                        ignore_index=True)\n",
    "        \n",
    "        #appel récursif --------------------------------------------------------------------------------\n",
    "        #print(\"debug-->début fnph_traitementrep\", str(datetime.now()))\n",
    "        list_rep_nb = fnph_traitementrep(join(parm_rep,onerep), parm_dicotypes, parm_mydb, parm_df_log_cols)\n",
    "        #print(\"debug-->fin   fnph_traitementrep\", str(datetime.now()))\n",
    "        #print('debug-->retour appel fnph_traitementrep -> list_rep_nb:',list_rep_nb, 'type=', type(list_rep_nb))\n",
    "        #appel récursif --------------------------------------------------------------------------------\n",
    "        if type(list_rep_nb)==list:\n",
    "            nbtot_insert    +=list_rep_nb[0]\n",
    "            nbtot_update    +=list_rep_nb[1]\n",
    "            local_log_nb_rep+=list_rep_nb[2]\n",
    "            local_df_log     =local_df_log.append(list_rep_nb[3])\n",
    "\n",
    "    #print(\"debug-->fin boucle onerep \"+str(datetime.now()))\n",
    "    #----------------------------------------------\n",
    "    #2)traitement des fichiers du répertoire courant avec insert et/ou update dans la fonction fnph_cat_filesononedirectory()\n",
    "    #----------------------------------------------\n",
    "    #print('debug-->Recherche des fichiers------')       \n",
    "    #appel à la fonction de traitement des fichiers du répertoire \n",
    "    # (recherche des fichiers dans le répertoire, de leurs metadonnées et mise à jour de la bd)\n",
    "    loc_debut_time=datetime.now() #debug : pour avoir une idée de la durée de l'appel (insertion/update)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    list_files_nb = fnph_cat_filesofonedirectory(parm_rep, parm_dicotypes, parm_mydb)\n",
    "    #--------------------------------------------------------------------------------\n",
    "    loc_fin_time  =datetime.now() #\n",
    "    loc_duree = loc_fin_time - loc_debut_time\n",
    "    if type(list_files_nb)==list:\n",
    "        nbtot_insert+=list_files_nb[0]\n",
    "        nbtot_update+=list_files_nb[1]\n",
    "        #ce print pour aller à la ligne après les sys.stdout.write dans fnph_cat_filesofonedirectory\n",
    "        #print(\" <... (put in bd:\" + str(list_files_nb[0]+list_files_nb[1]) + \")>\") \n",
    "        #sys.stdout.write(\"\\r\" + \"<sys3\" +\n",
    "        #           str(list_files_nb[0]+list_files_nb[1]) + \n",
    "        #           \"/\" + str(nbtot_insert+nbtot_update) + \" files\" +\n",
    "        #           #\"-d:\"+str(loc_debut_time) + \"-f:\"+str(loc_fin_time) +\n",
    "        #           \" - durée : \" + str(loc_duree).split('.')[0] + \"finsys3>\" ) \n",
    "        #sys.stdout.flush()\n",
    "        #\n",
    "    #ajout (append) du répertoire traité 'parm_rep' dans le df historique\n",
    "    local_df_log     = local_df_log.append({ 'unique_id'        :  global_unique_id,\n",
    "                                             'time'              : str(datetime.now()),\n",
    "                                             'rep_explored'      : parm_rep,\n",
    "                                             'nb_sous_rep'       : len(liste_repertoires), \n",
    "                                             'nb_of_files'       : list_files_nb[0]+list_files_nb[1],\n",
    "                                             'nb_of_files_cumul' : nbtot_insert+nbtot_update,\n",
    "                                             'comment'           : \"\"}, \n",
    "                                             ignore_index=True) \n",
    "    \n",
    "\n",
    "    #print('debug-->fin trait rep', parm_rep, 'retour(local_log_nb_rep)=',local_log_nb_rep)\n",
    "    return [nbtot_insert, nbtot_update, local_log_nb_rep, local_df_log]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test appel fnph_traitementrep\n",
    "\n",
    "start_time=datetime.now()\n",
    "GLOBAL_NUM_FLDR=0\n",
    "GLOBAL_NBTOTFILES_TREATED=0\n",
    "strtimestamp = str(datetime.timestamp(datetime.now()))\n",
    "global_unique_id = strtimestamp\n",
    "monRepertoire_totalnb_fldrs=10 #forcé pour test\n",
    "monRepertoire_totalnb_files=10 #forcé pour test\n",
    "\n",
    "#connection au serveur mongodb 27017, base test\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "mycollection = mydb[\"test_documents\"]\n",
    "#ou encore mycollection = client.prjph_catalogue.test_documents\n",
    "\n",
    "#testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\diximages\"\n",
    "#testRepertoire = '\\\\\\\\DESKTOP-AQNKR8B\\\\Pictures'\n",
    "testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\uneimage\"\n",
    "\n",
    "mydico_types={'.JPG':'image','.jpg':'image'}\n",
    "mynbrep=0\n",
    "mydflog=pd.DataFrame([{'time':str(datetime.now()),'rep_explored':'a path', 'comment':'test'}])\n",
    "fnph_traitementrep(testRepertoire, mydico_types, mydb, mydflog.columns)\n",
    "mydflog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getimage(parm_path, parm_file, parm_db):\n",
    "    \"\"\"\n",
    "    Cette fonction convertit un fichier image en une donnée stockable dans mongodb\n",
    "    Elle restitue les métadonnées à stocker dans la base mongo (passée en paramètres pour le stockage intermédaire je suppose)\n",
    "    \"\"\"\n",
    "    #print('.............<fnph_getimage>..............')\n",
    "\n",
    "    \n",
    "    #from pymongo import MongoClient\n",
    "    #import gridfs\n",
    "    #pip install opencv-python (pour cv2)\n",
    "    #import cv2\n",
    "    #import os\n",
    "    \n",
    "    pathfile=os.path.join(parm_path, parm_file)\n",
    "\n",
    "    # access our image collection\n",
    "    #client = MongoClient('localhost', 27017)\n",
    "    #db = client['prjph_catalogue']\n",
    "    #testCollection = db['test_documents']\n",
    "    fs = gridfs.GridFS(parm_db) #donc envoyer client['prjph_catalogue'] dans parm_db\n",
    "\n",
    "    # read the image and convert it to RGB\n",
    "    myfile=pathfile\n",
    "\n",
    "    image = cv2.imread(myfile)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # convert ndarray to string\n",
    "    imageString = image.tostring()\n",
    "\n",
    "    # store the image (stockage intermédiaire quelquepart dans la base avant insertion des métadonnées)\n",
    "    imageID = fs.put(imageString, encoding='utf-8')\n",
    "\n",
    "    # create our image meta data \n",
    "    meta = {\n",
    "        'name': parm_file,\n",
    "        'images': [\n",
    "            {\n",
    "                'imageID': imageID,\n",
    "                'shape': image.shape,\n",
    "                'dtype': str(image.dtype)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_retreive_image(parm_filename, parm_mydb, parm_mycollection):\n",
    "    #see https://stackoverflow.com/questions/49493493/python-store-cv-image-in-mongodb-gridfs\n",
    "    \"\"\"\n",
    "    Fonction retreive image dans mongo pour affichage de l'image stockée avec la fonction getimages\n",
    "    \"\"\"\n",
    "    \n",
    "    #Retreive\n",
    "    #import numpy as np\n",
    "    #import gridfs\n",
    "    #from matplotlib import pyplot as plt\n",
    "\n",
    "    #base\n",
    "    #client = pymongo.MongoClient('localhost',27017)\n",
    "    #mydb = client[\"prjph_catalogue\"]\n",
    "    #mycollection = mydb[\"test_documents\"]\n",
    "\n",
    "    #nom de l'image à récupérer (valeur du champ 'name')\n",
    "    #parm_name = parm_filename\n",
    "\n",
    "    # get the image meta data\n",
    "    image = parm_mycollection.find_one({'name': parm_filename})['images'][0]\n",
    "\n",
    "    # get the image from gridfs\n",
    "    fs = gridfs.GridFS(mydb) #donc envoyer client['prjph_catalogue'] dans parm_db\n",
    "\n",
    "    gOut = fs.get(image['imageID'])\n",
    "\n",
    "    # convert bytes to ndarray\n",
    "    img = np.frombuffer(gOut.read(), dtype=np.uint8)\n",
    "\n",
    "    # reshape to match the image size\n",
    "    img = np.reshape(img, image['shape'])\n",
    "\n",
    "    #Affichage\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test fnph_retreive_image\n",
    "\n",
    "#filename='Capturenb.JPG'\n",
    "\n",
    "#testimage=fnph_retreive_image(filename, mydb, mycollection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de calcul du nombre et de la taille totale des fichiers catalgués dans la base\n",
    "\n",
    "def fnph_clc_nb_st_size_tot(parm_collection):\n",
    "    \"\"\"\n",
    "    Fonction de calcul du nombre et de la taille totale des fichiers catalgués dans la base\n",
    "    retourne une liste de deux éléments : taille, nombre\n",
    "    \"\"\"\n",
    "    #Requête aggrégation\n",
    "    totalSize = parm_collection.aggregate(\n",
    "       [\n",
    "         {\n",
    "           \"$group\":\n",
    "             {\n",
    "               \"_id\"        : \"\",\n",
    "               \"totalSize\"  : { \"$sum\": \"$stats.st_size\" },\n",
    "               \"count\"      : { \"$sum\": 1 }\n",
    "             }\n",
    "         }\n",
    "       ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    reslist=list(totalSize)[0]\n",
    "    result=[reslist['totalSize'], reslist['count']]\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test appel fonction fnph_clc_nb_st_size_tot\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "mycollection = mydb[\"test_documents\"]\n",
    "\n",
    "fnph_clc_nb_st_size_tot(mycollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test fnph_getimage\n",
    "\n",
    "testRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\diximages\"\n",
    "testfile='Captureph1.jpg'\n",
    "testfile='Capturenb.JPG'\n",
    "\n",
    "testmeta=fnph_getimage(testRepertoire,testfile, mydb)\n",
    "\n",
    "testmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_get_video_properties(filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Récupère les metadata du fichier avec la bibliothèque 'hachoir'\n",
    "    \"\"\"\n",
    "    #!pip3 install hachoir\n",
    "    #import subprocess\n",
    "    \n",
    "    getresult_ok=True\n",
    "    try:\n",
    "        result = subprocess.Popen(['hachoir-metadata', filename, '--raw', '--level=3'],\n",
    "            stdout = subprocess.PIPE, stderr = subprocess.STDOUT)\n",
    "    except:\n",
    "        msg_err=\"ERREUR result=subprocess... dans fnph_get_video_properties pour le fichier \" + filename\n",
    "        getresult_ok=False\n",
    "    \n",
    "    if getresult_ok:\n",
    "        results = result.stdout.read().decode('utf-8').split('\\r\\n')\n",
    "\n",
    "        properties = {}\n",
    "        #formatage des données duration, width, height\n",
    "        for item in results:\n",
    "\n",
    "            if item.startswith('- duration: '):\n",
    "                duration = item.lstrip('- duration: ')\n",
    "                if '.' in duration:\n",
    "                    #t = datetime.datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S.%f')\n",
    "                    t = datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S.%f')\n",
    "                else:\n",
    "                    #t = datetime.datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S')\n",
    "                    t = datetime.strptime(item.lstrip('- duration: '), '%H:%M:%S')\n",
    "                seconds = (t.microsecond / 1e6) + t.second + (t.minute * 60) + (t.hour * 3600)\n",
    "                properties['duration'] = round(seconds)\n",
    "\n",
    "            if item.startswith('- width: '):\n",
    "                properties['width'] = int(item.lstrip('- width: '))\n",
    "\n",
    "            if item.startswith('- height: '):\n",
    "                properties['height'] = int(item.lstrip('- height: '))\n",
    "\n",
    "        #ajout de toutes les données (yc duration, width, height)\n",
    "        #properties['metadata_all']=results                                 <<<<<<<<<<<<< A TESTER\n",
    "        \n",
    "    else:\n",
    "        properties={'msg_err':msg_err}\n",
    "        \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test appel fnph_get_video_properties\n",
    "monRepertoire = r\"C:\\Users\\LENOVO\\Videos\\Captures\"\n",
    "monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\Fichiers_MOV\"\n",
    "monFichier = \"IMG_0578.MOV\"\n",
    "\n",
    "myfile=os.path.join(monRepertoire,monFichier)\n",
    "fnph_get_video_properties(myfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_startandend_ajout_evnmtppl_mongodb(parm_state,        parm_titretraitement, parm_dir,   parm_types, \n",
    "                                            parm_mycollection, parm_tailletot,       parm_nbtot, parm_nb_insupd,\n",
    "                                            parm_nb_rep,       parm_duration):\n",
    "\n",
    "    \"\"\"\n",
    "    parm_state indique s'il s'agit du début du traitement (\"début\")\n",
    "        alors on regarde s'il faut écrire eventgnl_000000000\n",
    "    ou s'il s'agit de la fin de traitement (\"fin\") \n",
    "        alors on écrit les stats\n",
    "    fonction d'écriture dans la base mongodb de l'événement 'traitement'\n",
    "    on écrit un événement avec les éléments suivants\n",
    "    - identifiant événement\n",
    "    - date heure\n",
    "    - nom du traitement\n",
    "    - nom du répertoire exploré\n",
    "    - nombre de fichiers traités\n",
    "    - (nombre de fichiers image)\n",
    "    - (nombre de fichiers vidéo)\n",
    "    - nombre d'insersions\n",
    "    - nombre de mises à jour\n",
    "    - volume après traitement (cumul des tailles de fichiers)\n",
    "    - nombre total de documents \n",
    "    \"\"\"\n",
    "    \n",
    "    #print('.............<fnph_startandend_ajout_evnmtppl_mongodb>..............')\n",
    "\n",
    "    #Création des variables\n",
    "    dnow = datetime.now()\n",
    "    strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "    dnow=str(dnow)\n",
    "\n",
    "    #Création du dico\n",
    "\n",
    "\n",
    "    #on créée la donnée eventppl si elle n'existe pas déjà (cas de création de la base)\n",
    "    if parm_state==\"début\":\n",
    "        if not mycollection.count_documents({\"eventgnls.eventgnl_000000000.epname\":\"création\"}, limit=1):\n",
    "            #print('debug-->insert eventgnls.eventgnl_000000000')\n",
    "            mycollection.insert_one({\"eventgnls\":{\"eventgnl_000000000\":{\"epdate\":str(dnow),\"epname\":\"création\"}}})\n",
    "\n",
    "    if parm_state==\"fin\":\n",
    "    #Ecriture des données (mise à jour de eventppl - il n'y en a qu'un - par ajout d'un sous-document)   \n",
    "       #fieldname = 'eventgnls.eventgnl_'+str(strtimestamp)\n",
    "        fieldname = 'eventgnls.eventgnl_'+global_unique_id.replace('.','_') #on met l'identifiant unique utilisé \n",
    "                                                                            #pour tous les fichiers du même traitement\n",
    "               \n",
    "        #print('debug-->update eventgnls')\n",
    "        result = mycollection.update_many( \n",
    "                     {\"eventgnls.eventgnl_000000000.epname\":'création'}, #on cherche eventppl renseigné (il n'y en a qu'un)\n",
    "                     {'$set':{fieldname:{'epdate'           :str(dnow),  #ajout des données suivantes\n",
    "                                         'epname'           :parm_titretraitement,\n",
    "                                         'epdir'            :parm_dir,\n",
    "                                         'eptypes'          :parm_types,\n",
    "                                         'epnb_ins'         :parm_nb_insupd[0],\n",
    "                                         'epnb_upd'         :parm_nb_insupd[1],\n",
    "                                         'eptot_size_files' :parm_tailletot,\n",
    "                                         'epnb_files_in_bd' :parm_nbtot,\n",
    "                                         'epnb_rep_explored':parm_nb_rep,\n",
    "                                         'epduration_trtmt' :parm_duration\n",
    "                                         }}} )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnph_getstats_dir(parm_dir):\n",
    "\n",
    "    \"\"\"\n",
    "    Cette fonction renvoie le nombre de fichier et de sous-répertoires sur toute l'arborescence de parm_dir\n",
    "    \"\"\"\n",
    "    nb_files   = 0\n",
    "    nb_folders = 0\n",
    "\n",
    "    for _, dirnames, filenames in os.walk(parm_dir): # _ for 'root' not used here\n",
    "        nb_files   += len(filenames)\n",
    "        nb_folders += len(dirnames)\n",
    "\n",
    "    #print(\"{:,} files, {:,} folders\".format(files, folders))\n",
    "    return [nb_files, nb_folders]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test fnph_getstats_dir()\n",
    "path=r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\"\n",
    "path=r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\"\n",
    "\n",
    "fnph_getstats_dir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programme principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Programme principal\n",
    "#Lecture du catalogue de fichier et constitution du dictionnaire des données à insérer dans la base (fnp_listDirectory)\n",
    "#puis écriture dans la base de chaque fichier et de ses données s'il n'est pas déjà présent. Sinon, mise à jour de ses\n",
    "#données (ajout d'un événement).\n",
    "\n",
    "\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "#Paramètres utilisateurs***********************************************************************************\n",
    "\n",
    "#Répertoire de sauvegarde de l'historique des répertoires explorés\n",
    "parm_df_log_rep = r'C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_log'\n",
    "\n",
    "#Paramètres de connexion\n",
    "#------ Base  -------------------*\n",
    "#connection au serveur mongodb 27017, base test\n",
    "client = pymongo.MongoClient('localhost',27017)\n",
    "mydb = client[\"prjph_catalogue\"]\n",
    "\n",
    "#------ LIBELLE DU TRAITEMENT-------------*  #1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "montitre_traitement=\"Catalogue de fichiers - G:/SvgWhatsapp \" #Est systématiquement complété plus bas\n",
    "                                                                             #par monRepertoire\n",
    "#------ COLLECTION -------------------*      #2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "mycollection_name = \"test_documents\"        #TEST\n",
    "#mycollection_name = \"images_videos\"          #PREPROD\n",
    "#------ ---------- -------------------*\n",
    "mycollection = mydb[mycollection_name]\n",
    "#------ REPERTOIRE INITIAL ---------------*  #3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "#.........................................*\n",
    "#REPERTOIRES DE TEST (dans la collection test_documents)\n",
    "#.........................................*\n",
    "monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Pictures\\MyPhotos\"\n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Videos\\Captures\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Pictures\"\n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\diximages\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\MyPhotos\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #SUR LES .MOV UNIQUEMENT 181020 - 00h45 env (durée : qq minutes) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Picosmos\" #nouveaux types d'images : webp\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Svgd_iPhone\" ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\SvgWhatsapp\\iPhone de Patrice iPhone 5S\\Messages\\2019-06-06\\WhatsApp\\Coeur de kid\\Coeur de kid [1]\"\n",
    "#.........................................*\n",
    "#REPERTOIRES DE PREPROD (dans la collection images_videos)\n",
    "#.........................................*\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\De_DD_Verbatim\" #171020 - 00h33 environ. ko \n",
    "#monRepertoire = r\"C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_repertoire_test\\Nouveau dossier\" #pour résoudre pbl ouverture img=PIL....img\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\De_DD_Verbatim\" #171020 - 01h03 environ. ok (durée : 1h52)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Chiens\" #171020 - 16h00 env (durée : qq secondes)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Ecole\" #171020 - 16h05 env (durée : qq secondes)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #181020 - 00h22 env (durée : ...) ko (manque subprocess pour les mov)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #181020 - 00h57 env (durée : ...) ko (encore subprocess - pourtant corrigé -> ajout d'une exception)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos\" #181020 - 1h36 env (durée : 4h env) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Picosmos\" #181020 - 13h30 env (qq secondes) ok (nouveaux types d'images : webp)\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Svgd_iPhone\"\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos_classement\" #181020 - 17h env (45min) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\Photos_svg_sur_MyBook_le181122\" #181020 - 19h10 env (2h) ok\n",
    "#monRepertoire = r\"\\\\DESKTOP-AQNKR8B\\SvgWhatsapp\"\n",
    "#----------------------------------------------------------------------------*\n",
    "\n",
    "#ajout de monRepertoire à montitre_traitement\n",
    "montitre_traitement += \"(\"+monRepertoire+\")\"\n",
    "#------  TYPES DE FICHIERS  ------------------*\n",
    "#listes des extensions et leur label\n",
    "#Remarque : les contrôles se font sans la casse\n",
    "mes_types_images = {\n",
    "                '.BMP'  : 'image',                '.TIFF' : 'image',\n",
    "                '.tif'  : 'image',                '.JPEG' : 'image',\n",
    "                '.jpg'  : 'image',                '.jfif' : 'image',\n",
    "                '.pjpeg': 'image',                '.pgp'  : 'image',\n",
    "                '.GIF'  : 'image',                '.PNG'  : 'image',\n",
    "                '.svg'  : 'image',                '.webp' : 'image'\n",
    "                        }\n",
    "\n",
    "mes_types_videos = {\n",
    "                '.mp4' : 'video',                '.mov' : 'video',\n",
    "                '.avi' : 'video',                '.flv' : 'video',\n",
    "                '.wmv' : 'video',                '.mpeg': 'video',\n",
    "                '.mkv' : 'video',                '.asf' : 'video',\n",
    "                '.rm'  : 'video',                '.vob' : 'video',\n",
    "                '.ts'  : 'video',                '.dat' : 'video'\n",
    "                        }\n",
    "\n",
    "#mes_types_images = {'.xxx'  : 'pour test aucune image'}\n",
    "#mes_types_videos = {'.mov'  : 'pour test videos mov'  }\n",
    "\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "#fin Paramètres************************************************************************************************\n",
    "\n",
    "\n",
    "#----------------\n",
    "#DEBUT TRAITEMENT\n",
    "#----------------\n",
    "\n",
    "#----------------\n",
    "#initialisations\n",
    "#----------------\n",
    "\n",
    "#Compteurs\n",
    "log_nb_rep                = 0 #nombre de répertoires traités    \n",
    "GLOBAL_NUM_FLDR           = 0 #numéro du répertoire traité\n",
    "GLOBAL_NBTOTFILES_TREATED = 0 #nombre total de fichiers traités\n",
    "#df historique des répertoires traités\n",
    "df_log = pd.DataFrame(columns=['unique_id',\n",
    "                               'time',\n",
    "                               'rep_explored',\n",
    "                               'nb_sous_rep', 'nb_of_files', \n",
    "                               'nb_of_files_cumul', \n",
    "                               'comment'])\n",
    "#globa_unique_id : Variable de valeur unique pour rsgner unique_id lors des différents appels\n",
    "strtimestamp = str(datetime.timestamp(datetime.now()))\n",
    "global_unique_id = strtimestamp\n",
    "print('\\n           global_unique_id:', global_unique_id,'\\n')\n",
    "\n",
    "\n",
    "#teste l'existence du répertoire de sauvegarde du log avant de démarrer\n",
    "if not os.path.exists(parm_df_log_rep):\n",
    "    print('ERREUR : le répertoire de sauvegarde n''existe pas')\n",
    "    print('ERREUR : ' + parm_df_log_rep)\n",
    "    print('ERREUR : veuillez vérifier et relancer')\n",
    "    sys.exit(\"haa! errors! vérifier le nom du répertoire du log en paramètre et relancer\")\n",
    "\n",
    "#------------\n",
    "# TRAITEMENT\n",
    "#------------\n",
    "start_time=datetime.now()\n",
    "print('start..................... : ', start_time, '\\n')\n",
    "\n",
    "print('accès à', monRepertoire, 'pour récupérer le nombre de sous-répertoires et de fichiers...')\n",
    "print('...')\n",
    "monRepertoire_totalnb_files, monRepertoire_totalnb_fldrs = fnph_getstats_dir(monRepertoire) \n",
    "print('... ok') #- accès à', monRepertoire, 'pour récupérer le nombre de sous-répertoires et de fichiers...\\n')\n",
    "\n",
    "print(\"\\n**** Collection            :\", mycollection_name, \"****\\n\")\n",
    "print(\"**** Répertoire            :\"  , monRepertoire, \"****\\n\")\n",
    "print(\"****  nb folders (total)   :\"  , monRepertoire_totalnb_fldrs+1, \"****\\n\")\n",
    "print(\"****  nb files (tous types):\"  , monRepertoire_totalnb_files  , \"****\\n\" )\n",
    "\n",
    "print('remarque : les deux nombres après chaque répertoire correspondent')\n",
    "print('           au nombre de fichiers à la racine du répertoire et celui cumulé avec ceux des sous-répertoires')\n",
    "print('           de type recherché et qui ont été insérés ou mis à jours dans la base\\n')\n",
    "\n",
    "\n",
    "#ajout de la ligne start dans df_log \n",
    "#rmq : nb_sous_rep et nb_of_files sont les documents à la racine du répertoire, pas le total\n",
    "df_log=df_log.append({'unique_id'   :global_unique_id,\n",
    "                      'time'        :str(datetime.now()),\n",
    "                      'rep_explored':\" <--- début de traitement - <\"+montitre_traitement+\">-->\",\n",
    "                      'comment'     :\"start \"}, ignore_index=True)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#mise sous format lower pour comparaison sans prise en compte de la casse \n",
    "#(les extensions de fichiers lues sont mises en minuscules)\n",
    "# avec fusion des deux listes\n",
    "A, B = mes_types_images, mes_types_videos\n",
    "mydico_types = {key.lower():value for d in (A, B) for key,value in d.items()}\n",
    "\n",
    "#Début - insertion - Ajout de l'insertion d'un log + stats (taille globale et nombre de fichiers)\n",
    "fnph_startandend_ajout_evnmtppl_mongodb(\"début\",      montitre_traitement, monRepertoire, mydico_types, \n",
    "                                        mycollection, 0                  ,0             ,           [], \n",
    "                                        log_nb_rep, \"nb folders : \"+str(monRepertoire_totalnb_fldrs) +\n",
    "                                                    \"nb files   : \"+str(monRepertoire_totalnb_files) \n",
    "                                        )\n",
    "\n",
    "#incrémentation du nombre de répertoires traités (+1) et écriture dans le df log du traitement du répertoire initial\n",
    "#remarque : en fait, cette ligne (répertoire initial) sera réécrite par la fonction fnph_traitementrep avec\n",
    "#           les nombres correspondants de sous-répertoires. Je la laisse car elle permet d'identifier rapidement\n",
    "#           dans le df les répertoires de base de chaque traitement.\n",
    "log_nb_rep+=1\n",
    "df_log=df_log.append({'unique_id'   : global_unique_id,\n",
    "                      'time'        : str(datetime.now()),\n",
    "                      'rep_explored': monRepertoire,\n",
    "                      'comment'     :\"Répertoire initial\"}, ignore_index=True)\n",
    "\n",
    "#Appel pour traitement du répertoire initial et cumul des compteurs et du nombre de répertoires\n",
    "#---------------------------------------------------------------------------\n",
    "result = fnph_traitementrep(monRepertoire, mydico_types, mydb, df_log.columns)\n",
    "#---------------------------------------------------------------------------\n",
    "#print('debug-->trace')\n",
    "log_nb_rep+=result[2]\n",
    "#print('debug-->log_nb_rep=',result[2])\n",
    "df_log=df_log.append(result[3])\n",
    "\n",
    "#Calcul de la taille globale de la base et du nombre de fichiers présents dans la base\n",
    "var_tailletot, var_nbtot = fnph_clc_nb_st_size_tot(mycollection)\n",
    "\n",
    "#Fin - Ajout de l'insertion d'un log + stats (taille globale et nombre de fichiers)\n",
    "end_time=datetime.now()\n",
    "fnph_startandend_ajout_evnmtppl_mongodb(\"fin\",        montitre_traitement, monRepertoire, mydico_types, \n",
    "                                        mycollection, var_tailletot,       var_nbtot,     result,\n",
    "                                        log_nb_rep, str(end_time - start_time))\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "msg    = ['']*12\n",
    "end_time=datetime.now()\n",
    "msg[0] = '\\ndone----------------------------------------'\n",
    "msg[1] = 'nombre répertoires explorés       : ' + str(log_nb_rep)\n",
    "msg[2] = 'nombre de fichiers traités        : ' + str(result[0]+result[1])\n",
    "msg[3] = 'dont nb insertions                : ' + str(result[0])\n",
    "msg[4] = 'et   nb updates                   : ' + str(result[1])\n",
    "msg[5] = 'taille ttle des fichiers en base  : ' + str(var_tailletot)\n",
    "msg[6] = 'nombre ttl de  documents en base  : ' + str(var_nbtot)\n",
    "msg[7] = 'Durée du traitement               : ' + str(end_time - start_time)\n",
    "msg[8] = ''\n",
    "msg[9] = ''\n",
    "msg[10] = 'done----------------------------------------'\n",
    "for i in range(len(msg)):\n",
    "    if msg[i]!='':\n",
    "        print(msg[i])\n",
    "\n",
    "#svg du df pour enregistrement du répertoire traité dans un df historique.\n",
    "for i in range(len(msg)):\n",
    "    if msg[i]!=\"\":\n",
    "        df_log=df_log.append({'unique_id'   : global_unique_id,\n",
    "                              'time'        : str(end_time),\n",
    "                              'rep_explored': \" <--- \" + monRepertoire + \" --- fin de traitement --->\",\n",
    "                              'comment'     : msg[i]}, ignore_index=True)\n",
    "\n",
    "#Sauvegarde du df_log - nom complété de la collection et nom du répertoire exploré\n",
    "dnow = datetime.now()\n",
    "strtimestamp = str(datetime.timestamp(dnow)).replace('.','_')\n",
    "mypathlog=r'C:\\Users\\LENOVO\\Documents\\Projets\\Prj_photos\\Prjph_log'\n",
    "#df_log_filename='prjph_df_log_'+ str(strtimestamp) + '.csv'\n",
    "df_log_filename= 'prjph_df_log__' +                                   \\\n",
    "                    global_unique_id.replace('.','_') + \"__\" +        \\\n",
    "                    mycollection_name + \"__\" +                        \\\n",
    "                   (monRepertoire.split(\"\\\\\")[-1]).replace(' ','_') + \\\n",
    "                 '.csv' #référencement avec global_unique_id utilisé pour référencer les documents dans la base.\n",
    "df_log.to_csv(os.path.join(mypathlog,df_log_filename), sep='\\t')\n",
    "print('df_log savec into', mypathlog)\n",
    "\n",
    "print('\\nended..................... : ', end_time, '\\n')\n",
    "\n",
    "#Programme principal fin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)  \n",
    "pd.set_option('display.max_rows', df_log.shape[0]+1)\n",
    "df_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
